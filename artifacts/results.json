{
  "project": "section-routing-led-summarization",
  "config": "configs/smoke.yaml",
  "runs": [
    {
      "config_path": "configs/smoke.yaml",
      "environment": {
        "cuda_available": true,
        "cuda_device_count": 2,
        "cuda_name_0": "NVIDIA GeForce RTX 3090",
        "platform": "Linux-6.17.0-14-generic-x86_64-with-glibc2.39",
        "python": "3.12.3",
        "torch": "2.10.0+cu126"
      },
      "generation": {
        "max_new_tokens": 128,
        "num_beams": 2,
        "wall_time_sec": 15.874171257019043
      },
      "metrics": {
        "bertscore_f1": {
          "ci95": [
            0.8481717710693677,
            0.8645915965239207
          ],
          "mean": 0.8564819743235906
        },
        "nli_entail_minus_contra": {
          "ci95": [
            0.5217466004851303,
            0.8793120756949065
          ],
          "mean": 0.6991272423135039
        },
        "rouge1_f": {
          "ci95": [
            0.20883255743720094,
            0.28048706287032776
          ],
          "mean": 0.24473240738288862
        },
        "rouge2_f": {
          "ci95": [
            0.03830448599250362,
            0.061406583572405124
          ],
          "mean": 0.050822400216172924
        },
        "rougeL_f": {
          "ci95": [
            0.1386342114918959,
            0.1702702810219017
          ],
          "mean": 0.15449075993062306
        }
      },
      "num_examples": 24,
      "run_name": "ablation_no_routing_section_tokens_shared_lora",
      "run_type": "ablation_no_routing"
    },
    {
      "config_path": "configs/smoke.yaml",
      "environment": {
        "cuda_available": true,
        "cuda_device_count": 2,
        "cuda_name_0": "NVIDIA GeForce RTX 3090",
        "platform": "Linux-6.17.0-14-generic-x86_64-with-glibc2.39",
        "python": "3.12.3",
        "torch": "2.10.0+cu126"
      },
      "generation": {
        "max_new_tokens": 128,
        "num_beams": 2,
        "wall_time_sec": 15.638857364654541
      },
      "metrics": {
        "bertscore_f1": {
          "ci95": [
            0.863577714562416,
            0.8757663095369934
          ],
          "mean": 0.870141384502252
        },
        "nli_entail_minus_contra": {
          "ci95": [
            0.5050764440806234,
            0.9124021544586868
          ],
          "mean": 0.7392816775730656
        },
        "rouge1_f": {
          "ci95": [
            0.29326833565698635,
            0.33976963858120945
          ],
          "mean": 0.3166496389391815
        },
        "rouge2_f": {
          "ci95": [
            0.06131074903561112,
            0.1080527167608962
          ],
          "mean": 0.08288118959450637
        },
        "rougeL_f": {
          "ci95": [
            0.17297349592363442,
            0.21505331157702973
          ],
          "mean": 0.18909366342924563
        }
      },
      "num_examples": 24,
      "run_name": "baseline_shared_lora_no_section_tokens",
      "run_type": "baseline"
    },
    {
      "config_path": "configs/smoke.yaml",
      "environment": {
        "cuda_available": true,
        "cuda_device_count": 2,
        "cuda_name_0": "NVIDIA GeForce RTX 3090",
        "platform": "Linux-6.17.0-14-generic-x86_64-with-glibc2.39",
        "python": "3.12.3",
        "torch": "2.10.0+cu126"
      },
      "generation": {
        "max_new_tokens": 128,
        "num_beams": 2,
        "wall_time_sec": 16.02587342262268
      },
      "metrics": {
        "bertscore_f1": {
          "ci95": [
            0.8428485173111161,
            0.8632020105918249
          ],
          "mean": 0.8548735330502192
        },
        "nli_entail_minus_contra": {
          "ci95": [
            0.5728810104338966,
            0.899091154289393
          ],
          "mean": 0.7404432119850147
        },
        "rouge1_f": {
          "ci95": [
            0.19280266096494186,
            0.2682817802473532
          ],
          "mean": 0.23248543953582193
        },
        "rouge2_f": {
          "ci95": [
            0.03464721745664669,
            0.062212285708912865
          ],
          "mean": 0.049568559019630705
        },
        "rougeL_f": {
          "ci95": [
            0.12961081288805076,
            0.16793456021202954
          ],
          "mean": 0.1505135223218489
        }
      },
      "num_examples": 24,
      "run_name": "main_routed_lora_section_tokens_aux_loss",
      "run_type": "main"
    }
  ],
  "report_md": "artifacts/report.md"
}