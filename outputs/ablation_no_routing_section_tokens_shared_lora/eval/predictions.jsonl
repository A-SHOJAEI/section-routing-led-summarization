{"prediction": "with the use of a power spectrum method as lean, it was considered as lean, but it was not considered as lean, it was considered as lean, it was considered as lean, it was considered as lean, it was considered as lean, it was considered as lean, it was considered as lean, it was considered as lean, it was considered as lean, it was considered as lean, it was considered as lean, it was considered as lean, it was considered as lean, it was considered as lean, it was considered as lean, it was considered as lean, it was considered as lean, it was considered as lean,", "reference": "the short - term periodicities of the daily sunspot area fluctuations from august 1923 to october 1933 are discussed . for these data \n the correlative analysis indicates negative correlation for the periodicity of about @xmath0 days , but the power spectrum analysis indicates a statistically significant peak in this time interval . \n a new method of the diagnosis of an echo - effect in spectrum is proposed and it is stated that the 155-day periodicity is a harmonic of the periodicities from the interval of @xmath1 $ ] days .    the autocorrelation functions for the daily sunspot area fluctuations and for the fluctuations of the one rotation time interval in the northern hemisphere , separately for the whole solar cycle 16 and for the maximum activity period of this cycle do not show differences , especially in the interval of @xmath2 $ ] days . \n it proves against the thesis of the existence of strong positive fluctuations of the about @xmath0-day interval in the maximum activity period of the solar cycle 16 in the northern hemisphere . \n however , a similar analysis for data from the southern hemisphere indicates that there is the periodicity of about @xmath0 days in sunspot area data in the maximum activity period of the cycle 16 only .", "source_text": "<sec:other>\nfor about 20 years the problem of properties of short - term changes of solar activity has been considered extensively .\nmany investigators studied the short - term periodicities of the various indices of solar activity .\nseveral periodicities were detected , but the periodicities about 155 days and from the interval of @xmath3 $ ] days ( @xmath4 $ ] years ) are mentioned most often .\nfirst of them was discovered by @xcite in the occurence rate of gamma - ray flares detected by the gamma - ray spectrometer aboard the _ solar maximum mission ( smm ) .\nthis periodicity was confirmed for other solar flares data and for the same time period @xcite .\nit was also found in proton flares during solar cycles 19 and 20 @xcite , but it was not found in the solar flares data during solar cycles 22 @xcite .\n_    several autors confirmed above results for the daily sunspot area data . @xcite studied the sunspot data from 18741984 .\nshe found the 155-day periodicity in data records from 31 years .\nthis periodicity is always characteristic for one of the solar hemispheres ( the southern hemisphere for cycles 1215 and the northern hemisphere for cycles 1621 ) .\nmoreover , it is only present during epochs of maximum activity ( in episodes of 13 years ) .\nsimilarinvestigationswerecarriedoutby + @xcite .\nthey applied the same power spectrum method as lean , but the daily sunspot area data ( cycles 1221 ) were divided into 10 shorter time series .\nthe periodicities were searched for the frequency interval 57115 nhz ( 100200 days ) and for each of 10 time series .\nthe authors showed that the periodicity between 150160 days is statistically significant during all cycles from 16 to 21 .\nthe considered peaks were remained unaltered after removing the 11-year cycle and applying the power spectrum analysis .\n@xcite used the wavelet technique for the daily sunspot areas between 1874 and 1993 .\nthey determined the epochs of appearance of this periodicity and concluded that it presents around the maximum activity period in cycles 16 to 21 .\nmoreover , the power of this periodicity started growing at cycle 19 , decreased in cycles 20 and 21 and disappered after cycle 21 .\nsimilaranalyseswerepresentedby + @xcite , but for sunspot number , solar wind plasma , interplanetary magnetic field and geomagnetic activity index @xmath5 .\nduring 1964 - 2000 the sunspot number wavelet power of periods less than one year shows a cyclic evolution with the phase of the solar cycle.the 154-day period is prominent and its strenth is stronger around the 1982 - 1984 interval in almost all solar wind parameters .\nthe existence of the 156-day periodicity in sunspot data were confirmed by @xcite .\nthey considered the possible relation between the 475-day ( 1.3-year ) and 156-day periodicities .\nthe 475-day ( 1.3-year ) periodicity was also detected in variations of the interplanetary magnetic field , geomagnetic activity helioseismic data and in the solar wind speed @xcite .\n@xcite concluded that the region of larger wavelet power shifts from 475-day ( 1.3-year ) period to 620-day ( 1.7-year ) period and then back to 475-day ( 1.3-year ) .\nthe periodicities from the interval @xmath6 $ ] days ( @xmath4 $ ] years ) have been considered from 1968 .\n@xcite mentioned a 16.3-month ( 490-day ) periodicity in the sunspot numbers and in the geomagnetic data .\n@xcite analysed the occurrence rate of major flares during solar cycles 19 .\nthey found a 18-month ( 540-day ) periodicity in flare rate of the norhern hemisphere .\n@xcite confirmed this result for the @xmath7 flare data for solar cycles 20 and 21 and found a peak in the power spectra near 510540 days .\n@xcite found a 17-month ( 510-day ) periodicity of sunspot groups and their areas from 1969 to 1986 .\nthese authors concluded that the length of this period is variable and the reason of this periodicity is still not understood .\n@xcite and + @xcite obtained statistically significant peaks of power at around 158 days for d"}
{"prediction": "the interferometer detectors are now under operation and awaiting the first signal of gws  @xcite. nomineit is believed that the direct detection of gravitational waves ( gws ) will bring the era of gravitational wave astronomy. nominethe interferometer detectors are now under operation and awaiting the first signal of gws  @xcite. nomineit is also known that pulsar timing arrays ( ptas ) can be used as a detector for gws @xcite. nominethese detectors are used to search for very low frequency ( @xmath0 ) gravitational waves, where the lower limit of the observable frequencies is determined by", "reference": "we study the detectability of circular polarization in a stochastic gravitational wave background from various sources such as supermassive black hole binaries , cosmic strings , and inflation in the early universe with pulsar timing arrays . \n we calculate generalized overlap reduction functions for the circularly polarized stochastic gravitational wave background . \n we find that the circular polarization can not be detected for an isotropic background . however , there is a chance to observe the circular polarization for an anisotropic gravitational wave background . \n we also show how to separate polarized gravitational waves from unpolarized gravitational waves .", "source_text": "<sec:other>\nit is believed that the direct detection of gravitational waves ( gws ) will bring the era of gravitational wave astronomy .\nthe interferometer detectors are now under operation and awaiting the first signal of gws  @xcite .\nit is also known that pulsar timing arrays ( ptas ) can be used as a detector for gws @xcite .\nthese detectors are used to search for very low frequency ( @xmath0 ) gravitational waves , where the lower limit of the observable frequencies is determined by the inverse of total observation time @xmath1 .\nindeed , the total observation time has a crucial role in ptas , because ptas are most sensitive near the lower edge of observable frequencies @xcite . taking into account its sensitivity ,\nthe first direct detection of the gravitational waves might be achieved by ptas .\nthe main target of ptas is the stochastic gravitational wave background ( sgwb ) generated by a large number of unresolved sources with the astrophysical origin or the cosmological origin in the early universe .\nthe promising sources are super massive black hole binaries  @xcite , cosmic ( super)string  @xcite , and inflation  @xcite .\nprevious studies have assumed that the sgwb is isotropic and unpolarized  @xcite .\nthese assumptions are reasonable for the primary detection of the sgwb , but the deviation from the isotropy and the polarizations should have rich information of sources of gravitational waves .\nrecently , the cross - correlation formalism has been generalized to deal with anisotropy in the sgwb @xcite .\nresult of this work enables us to consider arbitrary levels of anisotropy , and a bayesian approach was performed by using this formalism @xcite . on the other hand , for the anisotropy of the sgwb , the cross - correlation formalism has been also developed in the case of interferometer detectors  @xcite .\nas to the polarization , there are works including the ones motivated by the modified gravity  @xcite\n. we can envisage supermassive black hole binaries emit circularly polarized sgwb due to the chern - simons term  @xcite .\nthere may also exist cosmological sgwb with circular polarization in the presence of parity violating term in gravity sector  @xcite .    in this paper\n, we investigate the detectability of circular polarization in the sgwb by ptas .\nwe characterize sgwb by the so called stokes @xmath2 parameter  @xcite and calculate generalized overlap reduction functions ( orfs ) so that we can probe the circular polarization of the sgwb .\nwe also discuss a method to separate the intensity ( @xmath3 mode ) and circular polarization ( @xmath2 mode ) of the sgwb .\nthe paper is organized as follows . in section [ sec :\nstokes parameters for a plane gravitational wave ] , we introduce the stokes parameters for monochromatic plane gravitational waves , and clarify the physical meaning of the stokes parameters @xmath3 and @xmath2 . in section [ sec : formulation ] , we formulate the cross - correlation formalism for anisotropic circularly polarized sgwb with ptas .\nthe basic framework is essentially a combination of the formalism of @xcite , and the polarization decomposition formula of the sgwb derived in @xcite . in section [ sec : the generalized overlap reduction function for circular polarization ] , we calculate the generalized orfs for the @xmath2 mode .\nthe results for @xmath3 mode are consistent with the previous work  @xcite . in section [ sec : separation method ] , we give a method for separation between the @xmath3 mode and @xmath2 mode of the sgwb .\nthe final section is devoted to the conclusion . in appendixes , we present analytic results for the generalized overlap reduction functions . in this paper\n, we will use the gravitational units @xmath4 .\nlet us consider the stokes parameters for plane waves traveling in the direction @xmath5 , which can be described by @xmath6 \\\n, \\\\ & & h_{xy}(t , z)=h_{yx}(t , z)={\\rm re}[b_{\\times}\\mathrm{e}^{-iw(t - z ) } ] \\ .\\end{aligned}\\ ] ] for an idealized mono"}
{"prediction": "as a common quantum phenomenon, the tunneling through a potential barrier plays a very important role in the microscopic world and has been studied extensively since the birth of quantum mechanics. The tunneling effect governs many other nuclear processes such as fission and fusion. The tunneling effect governs many other nuclear processes such as fission and fusion. The tunneling effect governs also many other nuclear processes such as fission and fusion. The tunneling effect governs also many other nuclear processes such as fission and fusion. The tunneling effect governs also many other nuclear processes such as fission and fusion. The tunneling effect governs also many other nuclear processes", "reference": "starting from the wkb approximation , a new barrier penetration formula is proposed for potential barriers containing a long - range coulomb interaction . \n this formula is especially proper for the barrier penetration with penetration energy much lower than the coulomb barrier . \n the penetrabilities calculated from the new formula agree well with the results from the wkb method . as a first attempt , \n this new formula is used to evaluate @xmath0 decay half - lives of atomic nuclei and a good agreement with the experiment is obtained .", "source_text": "<sec:other>\nas a common quantum phenomenon , the tunneling through a potential barrier plays a very important role in the microscopic world and has been studied extensively since the birth of quantum mechanics .\none of the earliest applications of quantum tunneling is the explanation of @xmath0 decays in atomic nuclei .\nthe quantum tunneling effect governs also many other nuclear processes such as fission and fusion .\nin particular , a lot of new features are revealed in sub - barrier fusion reactions which are closely connected with the tunneling phenomena  @xcite .    for most of the potential barriers , the penetrability can not be calculated analytically  @xcite . among those potentials for which analytical solutions can be obtained ,\nthe parabolic potential  @xcite is the mostly used in the study of nuclear fusion . by approximating the coulomb barrier to a parabola\n, wong derived an analytic expression for the fusion cross section  @xcite which is widely adopted today in the study of heavy ion reactions ( see , e.g. , recent refs .\nthe parabolic approximation works remarkably well both for the penetrability and for the fusion cross section at energies around or above the coulomb barrier  @xcite .\napparently the parabolic approximation breaks down at energies much smaller than the barrier height due to the long - range coulomb interaction .\none may calculate the penetration probability numerically by using the path integral method or the wkb approximation .\nhowever , it is highly desirable to have an analytical expression for the barrier penetrability when one introduces an energy - dependent one - dimensional potential barrier  @xcite or barrier distribution functions  @xcite .    in the present work\n, we derived a new barrier penetration formula based on the wkb approximation .\nthe influence of the long coulomb tail in the barrier potential is taken into accout properly .\ntherefore this formula is especially applicable to the barrier penetration with penetration energy much lower than the coulomb barrier .    as a first attempt and a test study\n, we apply this new formula to evaluate @xmath0 decay half - lives of atomic nuclei . for the @xmath0 decay ,\nthe penetrability is usually calculated with the wkb approach  @xcite , in other words , integrating numerically the wave number within two turning points at which the interaction potential is equal to the @xmath1-value of the @xmath0 decay .\nwe will show that the present analytical formula reproduces the experimental results very well , especially for spherical nuclei .\nthe paper is organized as follows . in sec .\n[ sec : formalism ] we present the new barrier penetration formula .\nthe validity of the new formula is investigated and its application to @xmath0 decays are given in sec .\n[ sec : results ] . finally in sec .\n[ sec : summary ] we summarize our work . in the appendix ,\nthe detailed derivation of the new penetration formula is given .\nwhen the penetration energy is well below the coulomb barrier , the barrier penetrability formula derived from the wkb approximation reads , @xmath2 ,   \\label{eq : wkb}\\ ] ] where the potential usually consists of three parts , the nuclear , the coulomb , and the centrifugal potentials , @xmath3 @xmath4 and @xmath5 are the inner and outer turning points determined by the relation @xmath6 .    by approximating @xmath7 to a parabola with the height @xmath8 and the width @xmath9 , eq .\n( [ eq : wkb ] ) is reduced as @xmath10 ,   \\label{eq : hw}\\ ] ] which has been widely used in the study of heavy ion reactions .    because of the long - range coulomb interaction , the coulomb barrier given in eq .\n( [ eq : potential ] ) has a long tail and is asymmetric .\nthus for the penetration well below the barrier , the parabolic approximation is not valid .\nwe may divide the potential barrier into two parts at the barrier position @xmath11 .\nthe first part of @xmath7 with @xmath12 could still be approximated by half of a parabola and we need "}
{"prediction": "with the hybrid monte carlo algorithm ( hmc)@xcite and the hybrid monte carlo algorithm ( hmc)@xcite, often used to study quantum chromodynamics ( qcd ) on the lattice, one is interested in efficient numerical time integration schemes which are optimal in terms of computational costs per trajectory for a given acceptance rate. high order schemes are optimal in terms of computational costs per trajectory for a given acceptance rate.numerical methods allow the use of larger step sizes, but demand a larger computational effort per step ; low order schemes do not require such large computational costs per step, but need more", "reference": "we study a novel class of numerical integrators , the adapted nested force - gradient schemes , used within the molecular dynamics step of the hybrid monte carlo ( hmc ) algorithm . \n we test these methods in the schwinger model on the lattice , a well known benchmark problem . \n we derive the analytical basis of nested force - gradient type methods and demonstrate the advantage of the proposed approach , namely reduced computational costs compared with other numerical integration schemes in hmc .", "source_text": "<sec:other>\nfor the hybrid monte carlo algorithm ( hmc)@xcite , often used to study quantum chromodynamics ( qcd ) on the lattice , one is interested in efficient numerical time integration schemes which are optimal in terms of computational costs per trajectory for a given acceptance rate . high order\nnumerical methods allow the use of larger step sizes , but demand a larger computational effort per step ; low order schemes do not require such large computational costs per step , but need more steps per trajectory .\nso there is a need to balance these opposing effects .\nomelyan integration schemes @xcite of a force - gradient type have proved to be an efficient choice , since it is easy to obtain higher order schemes that demand a small additional computational effort .\nthese schemes use higher - order information from force - gradient terms to both increase the convergence of the method and decrease the size of the leading error coefficient . other ideas to achieve better efficiency for numerical time integrators are given by multirate or nested approaches .\nthese schemes do not increase the order but reduce the computational costs per path by recognizing the different dynamical time - scales generated by different parts of the action .\nslow forces , which are usually expensive to evaluate , need only to be sampled at low frequency while fast forces which are usually cheap to evaluate need to be sampled at a high frequency . a natural way to inherit the advantages from both force - gradient type schemes and multirate approaches would be to combine these two ideas .    previously , we studied the behavior of the adapted nested force - gradient scheme for the example of the @xmath0-body problem @xcite and would like to learn more about their usefulness for lattice field theory calculations . due to the huge computational effort required for qcd simulations ,\nit is natural to attempt an intermediate step first .\nwe chose the model problem of quantum electrodynamics ( qed ) in two dimensions , the schwinger model @xcite , since it is well - suited as a test case for new concepts and ideas which can be subsequently applied to more computationally demanding problems @xcite .\nas a lattice quantum field theory , it has many of the properties of more sophisticated models such as qcd , for example the numerical cost is still dominated by the fermion part of the action . the fact that this model , with far fewer degrees of freedom , does not require such large computational effort makes it the perfect choice for testing purposes .\nwe compare the behavior of numerical time integration schemes currently used for hmc @xcite with the nested force - gradient integrator @xcite and the adapted version introduced in @xcite .\nwe investigate the computational costs needed to perform numerical calculations , as well as the effort required to achieve a satisfactory acceptance rate during the hmc evolution .\nour goal is to find a numerical scheme for the hmc algorithm which would provide a sufficiently high acceptance rate while not drastically increasing the simulation time .\nthe paper is organized as follows . in section 2\nwe give a short overview of the hmc algorithm and numerical schemes for time integration , which are used in hmc . in section 3\nwe present the 2-dimensional schwinger model and introduce the idea of the force - gradient approach and the resulting novel class of numerical schemes .\nsection 4 is devoted to the results of a comparison between widely used algorithms and the new approach and section 5 draws our conclusion .\nin this section we provide a general overview of the hmc algorithm @xcite to introduce our novel integrator .\nwe also present some standard numerical time integrating methods used in hmc , as well state - of - the - art numerical schemes , which we later compare by applying them to the two - dimensional schwinger model .      in the hybrid monte carlo algorithm ,\nthe quantum lattice field theory is embedded in a "}
{"prediction": "the method for deriving functional equations proposed in ref. in ref. in sec. in sec. in sec. in sec. in sec. in sec. in sec. in sec. in sec. in sec. in sec. in sec. in sec. in sec. in sec. in sec. in sec. in sec. in sec. in sec. in sec. in sec. in sec. in sec. in sec. in sec. in sec. in sec. in sec. in sec. in sec. in sec. in sec. in sec. in sec. in sec. in sec. in sec", "reference": "new methods for obtaining functional equations for feynman integrals are presented . \n application of these methods for finding functional equations for various one- and two- loop integrals described in detail . \n it is shown that with the aid of functional equations feynman integrals in general kinematics can be expressed in terms of simpler integrals .    \n pacs numbers : 02.30.gp , 02.30.ks , 12.20.ds , 12.38.bx + keywords : feynman integrals , functional equations     +    derivation of functional equations for feynman integrals + from algebraic relations   +    * o.v .  \n tarasov * +   ii . \n institut fr theoretische physik , universitt hamburg , + luruper chaussee 149 , 22761 hamburg , germany + and + joint institute for nuclear research , + 141980 dubna , russian federation + : otarasov@jinr.ru +", "source_text": "<sec:other>\nrecently it was discovered that feynman integrals obey functional equations @xcite , @xcite .\ndifferent examples of functional equations were presented in refs .\n@xcite , @xcite,@xcite . in these articles\nonly one - loop integrals were considered .    in the present paper\nwe propose essentially new methods for deriving functional equations .\nthese methods are based on algebraic relations between propagators and they are suitable for deriving functional equations for multi - loop integrals . also these methods can be used to derive functional equations for integrals with some propagators raised to non - integer powers .\nour paper is organized as follows . in sec .\n2 . the method proposed in ref .  @xcite is shortly reviewed .    in sec .\n3 . a method for finding algebraic relations between products of propagators is formulated .\nwe describe in detail derivation of explicit relations for products of two , three and four propagators .\nalso algebraic relation for products of arbitrary number of proparators is given .\nthese relations are used in sec.4 . to obtain functional equations for some one- , as well as two- loop integrals .\nin particular functional equation for the massless one - loop vertex type integral is presented . also functional equation for the two - loop vertex type integral with arbitrary masses\nis given .    in sec .\nanother method for obtaining functional equations is proposed .\nthe method is based on finding algebraic relations for ` deformed propagators ' and further conversion of integrals with ` deformed propagators ' to usual feynman integrals by imposing conditions on deformation parameters . to perform such a conversion the @xmath0- parametric representation for both types of integrals\nis exploited .\nthe method was used to derive functional equation for the two - loop vacuum type integral with arbitrary masses . as a by product , from this functional equation we obtained new hypergeometric representation for the one - loop massless vertex integral .    in conclusion\nwe formulate our vision of the future applications and developments of the proposed methods .\nthe method for deriving functional equations proposed in ref .\n@xcite is based on the use different kind of recurrence relations . in particular in refs .\n@xcite , @xcite , @xcite , generalized recurrence relations @xcite were utilized to obtain functional equations for one - loop feynman integrals . in general such recurrence relations\nconnect a combination of some number of integrals @xmath1 corresponding to diagrams , say , with @xmath2 lines and integrals corresponding to diagrams with fewer number of lines . diagrams with fewer number of lines can be obtained by contracting some lines in integrals with @xmath2 lines .\nintegrals corresponding to such diagrams depend on fewer number of kinematical variables and masses compared to integrals with @xmath2 lines .\nsuch recurrence relations can be written in the following form : @xmath3 where @xmath4 and @xmath5 are ratios of polynomials depending on masses @xmath6 , scalar products @xmath7 of external momenta , powers of propagators @xmath8 and parameter of the space time dimension @xmath9 . at the left hand - side of eq .\n( [ nconnectr ] ) we combined integrals with @xmath2 lines and on the right hand - side integrals with fewer number of lines .    in accordance with the method of ref .\n@xcite , to obtain functional equation from eq .\n( [ nconnectr ] ) one should eliminate terms on the left hand - side by defining some kinematical variables from the set of equations : @xmath10 if there is a nontrivial solution of this system and for this solution some @xmath11 are different from zero then the right - hand side of eq .\n( [ nconnectr ] ) will represent functional equation .\nfor the one - loop integrals with @xmath2 propagators @xmath12 where @xmath13 different types of recurrence relations were given in refs .\n@xcite , @xcite .\ndiagram corresponding to this integral is given in figure 1 .\ne"}
{"prediction": "the sky hough procedure, designed mainly to reduce the discretization problem, and thus efficiencies, for both the procedures. in this paper, we present the basic scheme of the rome hierarchical procedure, designed mainly to reduce the discretization problem, and we compare it with the sky surveys, based on `` blind searches '', where the source parameters are unknown. in this case, we present the basic scheme of the rome hierarchical procedure, designed mainly to reduce the discretization problem, and we compare it with the sky hough procedure, which is actually used in the virgo collaboration. in this paper, we", "reference": "in the hierarchical search for periodic sources of gravitational waves , the candidate selection , in the incoherent step , can be performed with hough transform procedures . in this paper \n we analyze the problem of sensitivity loss due to discretization of the parameters space vs computing cost , comparing the properties of the sky hough procedure with those of a new frequency hough , which is based on a transformation from the _ time - observed frequency _ plane to the _ source frequency - spin down _ plane . \n results on simulated peakmaps suggest various advantages in favor of the use of the frequency hough . the ones which show up to really make the difference are 1 ) the possibility to enhance the frequency resolution without relevantly affecting the computing cost . \n this reduces the digitization effects ; 2 ) the excess of candidates due to local disturbances in some places of the sky map . \n they do not affect the new analysis because each map is constructed for only one position in the sky . \n + pacs . \n numbers : 04.80nn,07.05kf,97.60jd", "source_text": "<sec:other>\none of the main goals of the search for periodic isolated sources of gravitational waves ( g.w . ) is to perform all sky surveys , based on `` blind searches '' , where the source parameters are unknown . in this case\nhierarchical procedures are applied , based on a sequence of increasing resolution steps . in this paper\nwe study in details the problem of sensitivity loss due to discretization of parameters and to the needs to limit the computing cost , with hough procedures .\nin particular , we propose and study the characteristics of a frequency hough procedure , designed mainly to reduce the discretization problem , and we compare it with the sky hough procedure , which is actually used in the virgo collaboration .\n+ the paper is organized as follows : in sect .\n2 we present the basic scheme of the rome hierarchical procedure , based on the main idea of coincidences among subsets of data ; in sect .\n3 we discuss the limits due to digitization of the sky hough procedure ; in sects . 4 , 5 we present the new frequency hough procedure , discussing details its implementation and its basic characteristics ; in sect .\n6 we present the study of amplitude losses due to digitization , and thus efficiencies , for both the procedures .\nconclusions and comments are given in sect .\nhierarchical procedures , based on hough transform algorithms , are applied by various groups in the g.w . community .\nsee , for example , references @xcite .\nthere are various ways of implementing the hierarchical procedure and the hough transform .\nthe hough transform is a linear transform that is used to recognize the parameters of the analytical description of a curve from the position of some points on it .\nit operates on an `` image '' of points , in our case the peakmap in the time - frequency plane . for each peak of this map\nwe increase a set of bins of a multi - dimensional histogram ( in our case a two - dimensional histogram ) defined on the parameters space , called the hough map . in the old procedure ,\nthe parameter space was the position of the source , i.e. the celestial sphere , and we fixed the spin down value for each hough map . in the new one ,\nthe parameter space is the plane @xmath0 , and for each hough map , we fix the position of the source . the mapping ( i.e. which points of the hough map must be increased for a certain point in the peakmap ) can be done in different ways : we use always what we call the `` biunivocal mapping '' , i.e. a mapping in which every point in the hough map derive from a single point of the peakmap at a given time .\nit is easy to demonstrate that in this case the mapping is also uniform , i.e. in the case of uniformly distributed random dots in the peakmap , the expected value of the hough map @xmath1 is a constant ( for all parameter value ) .\nthis value , depending on the number n of the spectra of the peakmap and on the mapping , defines the `` noise '' of the map .\nit is binomially distributed with parameters n and @xmath2 .\nwe will refer here to the rome scheme , presently used in virgo data .\n[ fig : schema ] shows the basic scheme of the rome hierarchical procedure .\ndetails on the main aspects of the procedure are given in references @xcite .\nafter data cleaning ( short time domain disturbances removal ) and `` short ffts data base '' ( sfdb ) creation , peakmaps are computed , using a very refined auto - regressive algorithm to equalize the spectral data by an appropriate follow - up of the noise .\npeakmaps are frequency vs time maps , obtained from equalized spectra by selecting all the local maxima above a chosen threshold .\nan accurate cleaning of peakmaps , by removing known noise lines and the more persistent lines , is needed and its implementation is critical for the next step analysis . on the cleaned peakmaps ,\nmethods of peaks detection are applied .\nthat is , transformation from the input plane to the hough plane , thresholding and first order candidates selection .\ncandidat"}
{"prediction": "with a summary of overall results to date for each sn type of supernova ( cc  sne )is provided (   3 ), followed by a summary of overall results to date for each sn type of supernova ( cc  sne )is provided (   3 ), followed by a brief discussion of outstanding questions and areas in which future progress is likely (   5 ).with a summary of overall results to date for each sn type of supernova ( cc  sne )is provided (   3 ), followed by a brief discussion of outstanding questions and areas in which future progress is likely (   5", "reference": "i summarize what we have learned about the nature of stars that ultimately explode as core - collapse supernovae from the examination of images taken prior to the explosion . by registering pre - supernova and post - supernova images , usually taken at high resolution using either space - based optical detectors , or ground - based infrared detectors equipped with laser guide star adaptive optics systems , nearly three dozen core - collapse supernovae \n have now had the properties of their progenitor stars either directly measured or ( more commonly ) constrained by establishing upper limits on their luminosities . \n these studies enable direct comparison with stellar evolution models that , in turn , permit estimates of the progenitor stars physical characteristics to be made . \n i review progenitor characteristics ( or constraints ) inferred from this work for each of the major core - collapse supernova types ( ii - plateau , ii - linear , iib , iin , ib / c ) , with a particular focus on the analytical techniques used and the processes through which conclusions have been drawn . \n brief discussion of a few individual events is also provided , including sn 2005gl , a type iin supernova that is shown to have had an extremely luminous  and thus very massive  progenitor that exploded shortly after a violent , luminous blue variable - like eruption phase , contrary to standard theoretical predictions .", "source_text": "<sec:other>\nthis review focuses specifically on what we have learned about the progenitors of core - collapse supernovae ( cc  sne ) by examining images of the supernova ( sn ) sites taken prior to the explosion . by registering pre - sn and post - sn images , usually taken at high resolution using either space - based optical detectors , or ground - based infrared detectors equipped with laser guide star adaptive optics systems ( lgs - ao ) , about one dozen cc sn progenitors have now been directly detected ( i.e. , shown to be spatially coincident with the sn ) in pre - sn images , with roughly two dozen upper limits derived from non - detections @xcite .\nthis field has come a long way in the last decade , and promises to advance rapidly as more and more nearby galaxies  hosts of future cc sne  have high - resolution images added to the archive .\nthis review is organized as follows . following a brief summary of sn classification and stellar evolution theory (   2 ) , one example from each of the following three categories of progenitor studies\nis provided (   3 ; ordered from most - to - least common ) : ( 1 ) no progenitor star detected in pre - sn image(s ) ; ( 2 ) likely progenitor star identified via spatial coincidence in pre - sn and post - sn images ; ( 3 ) progenitor star detected in pre - sn image(s ) and subsequently confirmed by demonstrating its absence in images taken after the sn has faded beyond detection . a summary of overall results to date for each sn type\nis then given (   4 ) , followed by a brief discussion of outstanding questions and areas in which future progress is likely (   5 ) .\nnote that discussion is limited to what the examination of images of sn sites taken prior to the explosion has taught us , and necessarily excludes ( or relegates to very brief comment ) such related investigations as sn environments ( e.g. , @xcite ; see also the article by elias rosa in this volume ) and sn progenitor `` forensics '' ( e.g. , @xcite ; see also the article by modjaz in this volume ) . for a comprehensive discussion of all such related areas ,\nsee the recent review by @xcite .\nit is typical to subdivide cc  sne into at least five major categories ( see @xcite for a thorough review ) : ii - plateau ( ii - p ; hydrogen in spectrum and plateau in optical light curve ) , ii - linear ( ii - l ; hydrogen in spectrum , no plateau in optical light curve ) , iin ( hydrogen in spectrum and spectral and photometric evidence for interaction between sn ejecta and a dense circumstellar medium [ csm ] ) , iib ( hydrogen in spectrum initially , but transforms into a hydrogen - deficient spectrum at later times ) , and ib / c ( no evidence for hydrogen in spectrum at any time ) , where the ordering is a roughly increasing one in terms of inferred degree of envelope stripping prior to explosion ( i.e. , ii - p are the least stripped at the time of explosion , and ib / c are the most stripped ) .\nwhile most of this review focuses on the observational advances that have been made , theoretical input is critical to translate observed progenitor luminosity ( or limits ) into zero - age - main - sequence masses ( @xmath0 ) and stellar evolutionary states . among the most complete ( and accessiblestars . ] ) stellar evolution models at present are the metallicity - dependent models produced with the cambridge stellar evolution code , stars , the descendant of the code developed originally by @xcite and updated most recently by @xcite ( 2004 ; see also @xcite , and references therein ) , since they follow stellar evolution up to the initiation of core neon burning , which is likely to give an accurate indication of the pre - sn luminosity .\nthe hertzsprung - russell diagram ( hrd ) of the stars evolutionary tracks are shown in figure  1 for stars ranging in initial mass from @xmath1 .\ncomparison with other contemporary model grids ( e.g. , @xcite ; @xcite ) show that the endpoints for stars in the @xmath2 range differ by at most"}
{"prediction": "with a particular focus on a class of single - spin observables  @xcite, in particular, in particular within the last few years. Additionally,with a particular focus on a class of single - spin observables  @xcite, with a particular focus on a class of single - spin observables  @xcite, with a particular focus on a class of single - spin observables  @xcite. Additionally,they may be obtained for reactions in, for example, lepton - proton or proton - proton scattering with one transversely polarized initial proton, by dividing the difference of the cross sections", "reference": "we present a phenomenological study of the single - transverse spin asymmetry in azimuthal correlations of two jets produced nearly `` back - to - back '' in @xmath0 collisions at rhic . \n we properly take into account the initial- and final - state interactions of partons that can generate this asymmetry in qcd hard - scattering . using distribution functions fitted to the existing single - spin data , we make predictions for various weighted single - spin asymmetries in dijet correlations that are now readily testable at rhic .", "source_text": "<sec:other>\nsingle - transverse spin asymmetries ( ssas ) play a fundamental role for our understanding of qcd in high - energy hadronic scattering .\nthey may be obtained for reactions in , for example , lepton - proton or proton - proton scattering with one transversely polarized initial proton , by dividing the difference of the cross sections for the two settings of the transverse polarization by their sum .\nthere have been extensive experimental investigations of such asymmetries  @xcite .\nthese have initiated much theoretical progress , in particular within the last few years .\na particular focus has been on a class of single - spin observables that are characterized by a large momentum scale @xmath1 ( for example , the virtuality of the photon in deeply - inelastic scattering ( dis ) ) and by a much smaller , but also measured , transverse momentum @xmath2 .\nin such a `` two - scale '' situation , single - spin asymmetries may arise at leading power , that is , not suppressed by an inverse power of @xmath1 . for some of these cases ,\nfactorization theorems have been established  @xcite that allow to write the spin - dependent cross sections in terms of parton distribution functions and/or fragmentation functions , perturbative hard - scattering functions , and so - called soft factors .\na crucial feature is that the distribution functions and the soft factor in this factorization are not integrated over the transverse momenta of partons , because these in fact generate the observed transverse momentum @xmath2 . among other things\n, the observables may therefore provide valuable insights into the dependence of parton distributions in nucleons on transverse momentum .\nthis becomes particularly interesting when the nucleon is transversely polarized , because there may be correlations between the nucleon spin vector , its momentum , and the parton s transverse momentum .\none particular correlation , known as the `` sivers effect '' and described by so - called `` sivers functions ''  @xcite , is now widely believed to be involved in a variety of observed hadronic single - spin phenomena .\ncloser theoretical studies have revealed that the sivers effect plays an important role in qcd , beyond giving rise to phenomenological functions to be used in the description of single - spin asymmetries .\na particularly interesting feature is that the sivers effect is not universal in the usual sense , that is , it is not represented by universal probability functions convoluted with partonic hard - scattering cross sections .\nthis might at first sight appear to make the study of these functions less interesting .\nhowever , the non - universality has in fact a clear physical origin , and its closer investigation has turned out to be an extremely important and productive development in qcd . in a nutshell , in order not to be forced to vanish because of the time - reversal symmetry of qcd , single - spin asymmetries require the presence of a strong - interaction phase . for the sivers functions this phase originates from the `` gauge links '' in their definition  @xcite , which are path - ordered exponentials of the gluon field that make the functions gauge - invariant . in dis\n, the gauge link may be viewed as a rescattering of the parton in the color field of the nucleon remnant . that such a final - state rescattering may generate the phase required for a nonzero ssa in semi - inclusive hadron production in dis ( sidis ) was first discovered within a model calculation  @xcite .\ndepending on the hard - scattering process , the `` rescattering '' will however manifest itself in different ways .\nfor example , for drell - yan lepton pair production in hadronic scattering , _ initial - state _ , rather than final - state , interactions are relevant . as a result , the phase provided by the gauge links is opposite , and the sivers functions for the drell - yan process have opposite sign  @xcite . in more general terms ,\nthe nontrivial  univer"}
{"prediction": "the kingman coalescent is a random tree introduced by @xcite as the genealogy arising in large population genetic models.    for the kingman coalescentit has infinitely many leaves and is usually constructed from leaves to the root as follows : given that there are @xmath7 lines in the tree, after some exponential time with rate @xmath8, two lines are chosen uniformly and merged to one line, leaving the tree with @xmath9 lines. due to the quadratic rate @xmath10 the tree immediately comes down from infinitely to finitely many leaves @xcite. since the seminal paper", "reference": "kingman s coalescent is a random tree that arises from classical population genetic models such as the moran model . \n the individuals alive in these models correspond to the leaves in the tree and the following two laws of large numbers concerning the structure of the tree - top are well - known : ( i ) the ( shortest ) distance , denoted by @xmath0 , from the tree - top to the level when there are @xmath1 lines in the tree satisfies @xmath2 almost surely ; ( ii ) at time @xmath0 , the population is naturally partitioned in exactly @xmath1 families where individuals belong to the same family if they have a common ancestor at time @xmath0 in the past . if @xmath3 denotes the size of the @xmath4th family , then @xmath5 almost surely . for both laws of large numbers \n we prove corresponding large deviations results . for ( i ) , the rate of the large deviations is @xmath1 and we can give the rate function explicitly . for ( ii ) , the rate is @xmath1 for downwards deviations and @xmath6 for upwards deviations . for both cases \n we give the exact rate function .    \n =     =    =     =", "source_text": "<sec:other>\nkingman s coalescent is a random tree introduced by @xcite as the genealogy arising in large population genetic models .\nit has infinitely many leaves and is usually constructed from leaves to the root as follows : given that there are @xmath7 lines in the tree , after some exponential time with rate @xmath8 , two lines are chosen uniformly and merged to one line , leaving the tree with @xmath9 lines . due to the quadratic rate @xmath10 the tree immediately comes down from infinitely to finitely many leaves @xcite . since the seminal paper by @xcite this random tree has been generalized to other infinite trees arising in population genetics models .    for the kingman\ncoalescent some laws of large numbers and central limit theorems have been proved .\nthey are nicely summarized in @xcite , chapter  4.2 ; see also proposition  [ p:11 ] below . for @xmath11\nlet @xmath12 denote the number of lines time @xmath13 in the past .\nthen , since the kingman coalescent immediately comes down from infinity , @xmath12 is finite .\nfurthermore it is approximately @xmath14 .\nequivalently , the time @xmath0 it takes the coalescent to go from infinitely many lines to @xmath1 lines is approximately @xmath15 for large @xmath1 .\ngoing to the fine structure , at time @xmath0 the infinite population is decomposed in @xmath1 families ( whose joint distribution is exchangeable ) and every leaf in the tree belongs to exactly one of the @xmath1 families whose frequencies are denoted by @xmath16 .\nit is known that for large @xmath1 a randomly chosen @xmath3 is approximately exponentially distributed with mean @xmath17 .\nthis translates into several laws of large numbers ; see e.g.  ( 35 ) in @xcite .\nin particular the probability of picking ( from the initial infinite population ) two leaves that belong to the same family , given by @xmath18 , is approximately @xmath15 .    the main goal of the present paper is to study the corresponding large deviations results . to the best of our knowledge , except for @xcite , cf .\nremark  [ rem : angel ] , results in this direction are not present in the literature .\nwe formulate our results in the next section .\ntheorem  [ t1 ] gives a full large deviation principle for the distributions of @xmath19 .\nthe proof , given in section  [ sec : proofs1 ] , is an application of the grtner - ellis theorem . as a byproduct\n, we derive a large deviation principle for the distributions of @xmath20 in corollary  [ cor : tnt ] .\nlarge deviations of @xmath21 are considered in theorem  [ t2 ] and exact rate functions for downwards and upwards deviations are given . the proof is given in section  [ sec : proof - theorem - reft2 ] . for the upward deviations we use a variant of cramr s theorem for heavy - tailed random variables\n; see e.g.  @xcite . for the downward deviations we use a connection to self - normalized large deviations ; see @xcite .\nthis connection was pointed out to us by alain rouault and nina gantert .\nsince the rate function for downward deviations is hard to treat analytically we provide in theorem  [ t3 ] a simple lower bound .\nthe proof of that bound is given in section  [ sec : proof - theorem3 ] .\nthe kingman coalescent can be seen as a discrete graph , more precisely a discrete tree with infinitely many leaves .\nlet @xmath22 be independent exponentially distributed variables with mean @xmath23 .\nthen the kingman coalescent tree can be constructed from the root to the leaves as follows .    1 .\nstart the tree with two lines from the root .\n2 .   for @xmath24\nthe tree stays with @xmath7 lines for the amount of time @xmath25 .\nafter that time one of the @xmath7 lines is randomly chosen .\nthis line splits in two so that the number of lines jumps from @xmath7 to @xmath26 .\n3 .   stop upon reaching infinitely many lines , which happens after ( the almost surely finite ) time @xmath27 .\nthe random variable @xmath28 is the total tree height .\nalternatively , @xmath28 is the time to the most recent common"}
{"prediction": "the most remarkable results include the discovery of the concept of the dispersion management to _ temporal optical solitons _ and the discovery of the concept of the dispersion management to _ temporal optical solitons _ and the discovery of the concept of the dispersion management to _ temporal optical solitons _ and the discovery of the concept of the dispersion management to _ temporal optical solitons _ and the discovery of the concept of the dispersion managed soliton_. high - speed optical communications require effective components such as high - performance broadband computer networks that can be developed by employing the concept of the bit - parallel - wavelength ( b", "reference": "we discuss several novel types of multi - component ( temporal and spatial ) envelope solitary waves that appear in fiber and waveguide nonlinear optics . \n in particular , we describe multi - channel solitary waves in bit - parallel - wavelength fiber transmission systems for high performance computer networks , multi - colour parametric spatial solitary waves due to cascaded nonlinearities of quadratic materials , and quasiperiodic envelope solitons due to quasi - phase - matching in fibonacci optical superlattices .    2", "source_text": "<sec:other>\nrapid progress in the design and manufacture of optical fiber systems is a result of worldwide demand for ultra - high bit - rate optical communications .\nthis explains the growing interest of the soliton community in soliton - based optical fiber communication systems .\nthis area of research was considerably advanced in recent years  @xcite .\nthe most remarkable results include the application of the concept of the dispersion management to _ temporal optical solitons _ and soliton - based optical transmission systems , and the discovery of the so - called _ dispersion managed soliton_. high - speed optical communications require effective components such as high - performance broadband computer networks that can be developed by employing the concept of the bit - parallel - wavelength ( bpw ) pulse transmission that offers many of the advantages of both parallel fiber ribbon cable and conventional wavelength - division - multiplexing ( wdm ) systems  @xcite .\nexpanding development in the study of the soliton fiber systems has been observed in parallel with impressive research on their spatial counterparts , optical self - trapped beams or _\nspatial optical solitons_. one of the key concepts in this field came from the theory of multi - frequency wave mixing and cascaded nonlinearities where a nonlinear phase shift is produced as a result of the parametric wave interaction  @xcite .\nin all such systems , the nonlinear interaction between the waves of two ( or more ) frequencies is the major physical effect that can support coupled - mode multi - frequency solitary waves .\nthe examples of temporal and spatial solitons mentioned above have one common feature : they involve the study of solitary waves in multi - component nonlinear models .\nthe main purpose of this paper is to overview several different physical examples of multi - mode and/or multi - frequency solitary waves that occur for the pulse or beam propagation in nonlinear optical fibers and waveguides . for these purposes , we select three different cases : multi - wavelength solitary waves in bit - parallel - wavelength optical fiber links , multi - colour spatial solitons due to multistep cascading in optical waveguides with quadratic nonlinearities , and quasiperiodic solitons in the fibonacci superlattices .\nwe believe these examples display both the diversity and richness of the multi - mode soliton systems , and they will allow further progress to be made in the study of nonlinear waves in multi - component nonintegrable physical models .\nbecause the phenomenon of the long - distance propagation of _ temporal optical solitons _ in optical fibers  @xcite is known to a much broader community of researchers in optics and nonlinear physics , first we emphasize _ the difference between temporal and spatial solitary waves_. indeed , for a long time stationary beam propagation in planar waveguides has been considered somewhat similar to the pulse propagation in fibers .\nthis approach is based on the so - called _ spatio - temporal analogy _ in wave propagation , meaning that the propagation coordinate @xmath0 is treated as the evolution variable and the spatial beam profile along the transverse direction in waveguides , is similar to the temporal pulse profile in fibers .\nthis analogy is based on a simple notion that both beam evolution and pulse propagation can be described by the cubic nonlinear schrdinger ( nls ) equation .\nhowever , contrary to the widely accepted opinion , there is a crucial difference between temporal and spatial solitons . indeed , in the case of the nonstationary pulse propagation in fibers , the operation wavelength is usually selected near the zero point of the group - velocity dispersion .\nthis means that the absolute value of the fiber dispersion is small enough to be compensated by a weak nonlinearity such as that produced by the ( very weak ) kerr effect in optical fibers which leads to a relative nonlinearity - induced change i"}
{"prediction": "further, the above relation holds good if and only if the subsystems are in a mixed state. distinguisentanglement @xcite in a composite system refers to certain implicit correlation between the subsystems arising from their interaction. distinguisentanglement is the key resource of quantum computation and quantum information processing @xcite. distinguisentanglement is the key resource of quantum information processing @xcite. distinguisentanglement in a bipartite pure state is the key resource of quantum information processing @xcite. distinguisentanglement in a bipartite pure state is the key resource of quantum information", "reference": "strong subadditivity inequality for a three - particle composite system is an important inequality in quantum information theory which can be studied via a four - particle entangled state . \n we use two three - level atoms in @xmath0 configuration interacting with a two - mode cavity and the raman adiabatic passage technique for the production of the four - particle entangled state . using this four - particle entanglement \n , we study for the first time various aspects of the strong subadditivity inequality .", "source_text": "<sec:other>\nentanglement @xcite in a composite system refers to certain implicit correlation between the subsystems arising from their interaction .\nit is the key resource of quantum computation and quantum information processing @xcite .\ndue to recent advances in this field , entanglement has generated renewed interest .\nthere have been different approaches to understand and to quantify entanglement @xcite .\nbut so far the entanglement , only in a bipartite pure state has been investigated very extensively .\nthe von neumann entropy @xcite of either of the subsystems provides a good measure of entanglement in this case @xcite .\nthis is the quantum partner of the shannon s entropy @xcite in classical information theory and is defined as @xcite @xmath1 where @xmath2 . here , @xmath3 is the reduced density operator of the subsystem @xmath4 and is given by @xmath5 where @xmath6 is the density operator of the composite system under consideration and @xmath7 , @xmath8 .\nin general , the quantities @xmath9 satisfy the following inequality ( due to araki and lieb ) @xcite : @xmath10 where @xmath11 is the joint entropy of the composite system comprising @xmath12 and @xmath13 .\nthe second part of the above inequality is known as subadditivity inequality @xcite . for a pure state , @xmath14 and thus @xmath15 .\nthe equality sign in the above relation holds good if and only if the composite density matrix @xmath6 can be written as a tensor product of its two reduced density matrices @xmath16 and @xmath17 , i.e. , for a disentangled state .\none can define the index of correlation @xmath18 given by the expression @xmath19 @xcite , which can also be interpreted as information entropy in quantum information point of view .\nwe note that kim _\net al . _ have calculated the entropies of different kinds of pure states including two - mode fock states and squeezed states @xcite .\nfurther , the above relation for entropy has been studied in the context of entangled gaussian states @xcite .\nso far we have discussed about the measurement of entanglement in a bipartite pure state .\nif the composite system is in a mixed state ( defined by the density operator @xmath20 ) , the entanglement of formation @xmath21 can be defined in terms of the average von neumann entropies of the pure states of the decompositions @xcite .\nwootters has shown the quantity @xmath21 to be an explicit function of @xmath20 @xcite .\nhe has introduced the notion of concurrence in this context .\nwe further notice that from the schmidt decomposition of a pure bipartite state , one can properly identify the entanglement present in the state @xcite .\nthis is also very useful to study bipartite continuous systems @xcite . on the other hand , for a mixed state @xmath20 , the separability criterion has been proposed @xcite to study entanglement .\nthis is based on positive partial transpose mapping of @xmath20 .\nthus the negativity ( entanglement monotone ) of the eigenvalues of the partial transpose of @xmath20 could be a measure of entanglement in a mixed bipartite system @xcite .\nthe concept of negativity as an entanglement measure has been used in context of interaction of atoms with thermal field @xcite .\nthe separability criterion has been extended to continuous systems @xcite also .    despite many approaches to define entanglement for a bipartite system ,\nthere have been only a few approaches to quantify entanglement in the composite systems of three or more particles @xcite .\nwe note that a generalization of schmidt decomposition in multipartite systems in pure states has been introduced @xcite .\n@xcite proposed a measurement of entanglement in a tripartite system in terms of concurrences of the pairs of subsystems .\nthis measure is invariant under permutations of the subsystems .\nan average entanglement in a four - partite entangled state has been defined in terms of von neumann entropies of the pairs of subsystems @xcite .\nvery recently , yukalov has addressed the question more"}
{"prediction": "the finding of saio et al. subur( 2006 ) has prompted a few groups ( godart et al. subur2009, godart et al. subur2009, godart et al. subur2009, godart et al. subur2009, godart et al. subur2009, godart et al. subur2009, godart et al. subur2009, godart et al. subur2010, godart et al. subur( 2006 ) have detected pulsational frequencies in the most satellite data of the blue supergiant hd 163899 ( b2 ib / ii, klare & neckel 1977,", "reference": "evolutionary tracks and pulsational analysis of models with masses of 13 - 18 @xmath0 are presented . \n we address two important questions . the first one deals with one of the most unresolved problems in astrophysics , i.e. , the existence of a blue loop after core helium ignition ; the so called `` to loop or not to loop '' problem . \n we show that inward overshooting from the outer convective zone in the red giant phase is prerequisite for the development of the blue loop . \n our second question concerns pulsational instability of models in the core helium burning phase . \n we present for the first time that models on the blue loop can have unstable modes driven by the @xmath1 mechanism operating in the @xmath2bump . \n contrary to post - main sequence models in the shell hydrogen burning phases , pulsational instability of the blue loop models depends mainly on effective temperature and metallicity is of secondary importance . \n finally , we try to interpret the oscillation spectrum of the blue supergiant hd 163899 , the only member of the spbsg class , and to get some clue on the evolutionary status of the star .    \n [ firstpage ]    stars : early - type  stars : supergiants  stars : oscillations", "source_text": "<sec:other>\nslowly pulsating b - type supergiants ( spbsg ) have emerged as a new class of pulsating variables after saio et al .\n( 2006 ) have detected pulsational frequencies in the most satellite data of the blue supergiant hd 163899 ( b2 ib / ii , klare & neckel 1977 , schmidt & carruthers 1996 ) .\nsaio et al .\n( 2006 ) identified 48 frequency peaks in the most light curve and attributed them to g- and p - mode pulsations . because so far only one object of this type is found , the spbsg class is not yet well defined as for the range of effective temperature and luminosity .\nalso the evolutionary status of these pulsators remains unrevealed ; they may be either in the shell hydrogen burning phase as well as after core helium ignition .\nthe finding of saio et al .\n( 2006 ) has prompted a few groups ( godart et al .\n2009 , daszyska - daszkiewicz , ostrowski , pamyatnykh . 2013 ; hereafter d2013 ) to reanalyse pulsation stability in models of b - type stars after the terminal age main sequence ( tams ) and to further studies of spbsg variables .\nthe presence of g - mode pulsations in b - type post - main sequence stars has been explained by a partial reflection of some modes at an intermediate convective zone ( icz ) related to the hydrogen - burning shell or at a chemical gradient zone surrounding the radiative core .\nhowever , all studies of these objects published so far are based on the assumption that hd 163899 has not reached the phase of core helium ignition , i.e. , it is in the phase of shell hydrogen burning .\nthis assumption might not necessary be fulfilled , because the blue loop can reach temperatures of early b spectral types . in this paper\nwe calculate models which undergo core helium burning on the blue loop and compare them with models in the hydrogen shell burning phase .\nthe structure of the paper is as follows . in section\n[ domains ] , we present the new instability domains which include pulsational instability on the blue loops .\nthe effects of opacity , metallicity , overshooting , element diffusion and mass loss on the pulsational instability areas are studied .\npropagation diagrams and properties of instability parameter and kinetic energy of modes for representative models are described in section [ models ] . in section [ identification ]\nwe construct photometric diagnostic diagrams for the b - type supergiant models and discuss a prospect for mode identification . an attempt to interpret the oscillation spectrum of hd 163899\nis presented in section [ hd163899 ] .\nthe last section contains conclusions .\nthe evolutionary models were calculated with mesa evolution code ( modules for experiments in stellar astrophysics , paxton et al .\n2011 , paxton et al . 2013 ) .\nmesa allows to follow the evolution of massive stars to the pre - supernova phase . our previous calculations ( d2013 )\nwere limited to the phase before core helium ignition due to the lack of helium burning in warsaw - new jersey evolution code we used .\nwe considered the mass range of 13@xmath318 @xmath0 .\nall computed models have an initial hydrogen abundance of @xmath4 and agss09 metal mixture ( asplund et al .\nthe initial metal abundance varies from @xmath5 to @xmath6 .\nopal ( iglesias & rogers 1996 ) and op opacity tables ( seaton 2005 ) were used .\nall effects of rotation were neglected .\nnon - adiabatic pulsation analysis was performed using the code of dziembowski ( 1977 ) . in fig.[fig1 ] we present evolutionary tracks including various effects : opacity , metallicity , overshooting , mass loss and element diffusion .\nthey will be discussed in detail in the following subsections .\nthe convective zones are determined by the ledoux criterion .\nit seems to be more justified than the schwarzschild criterion because of a direct sensitivity of the chemical gradient to evolution .\nlebreton et al .\n( 2009 ) argued that the use of the ledoux criterion leads to a narrower icz and hence to the smaller number of unstable modes . in case of o"}
{"prediction": "dws are known in optical media, where they are formed by immiscible binary bose - einstein condensates ( becs ), as well as by immiscible binary bose - einstein condensates ( becs ), as well as by immiscible binary bose - einstein condensates ( becs ), as well as by immiscible binary bose - einstein condensates ( becs ), as well as by immiscible binary bose - einstein condensates ( becs ), as well as by immiscible binary bose - einstein", "reference": "we consider one - dimensional mixtures of an atomic bose - einstein condensate ( bec ) and tonks - giradeau ( tg ) gas . the mixture is modeled by a coupled system of the gross - pitaevskii equation for the bec and the quintic nonlinear schrdinger equation for the tg component . \n an immiscibility condition for the binary system is derived in a general form . under this condition , \n three types of bec - tg interfaces are considered : domain walls ( dws ) separating the two components ; bubble - drops ( bds ) , in the form of a drop of one component immersed into the other ( bds may be considered as bound states of two dws ) ; and bound states of bright and dark solitons ( bdss ) . \n the same model applies to the copropagation of two optical waves in a colloidal medium . \n the results are obtained by means of systematic numerical analysis , in combination with analytical thomas - fermi approximations ( tfas ) . using both methods , families of dw states \n are produced in a generic form . \n bd complexes exist solely in the form of a tg drop embedded into the bec background . on the contrary , \n bdss exist as bound states of tg bright and bec dark components , and vice versa .", "source_text": "<sec:other>\nbinary systems , whose behavior crucially depends on the underlying condition of immiscibility or miscibility @xcite , play a fundamentally important role in many areas of physics . in the case of immiscibility , a major effect is the formation of domain walls ( dws ) between regions occupied by immiscible components . commonly known are dws in media featuring a vectorial order parameter , such as ferromagnets @xcite , ferroelectrics @xcite , and liquid crystals @xcite . in self - defocusing optical media ,\ndws separate regions occupied by electromagnetic waves with orthogonal circular polarizations of light haelt , me .\nsimilar interface patterns were predicted in arrays of nonlinear optical waveguides , modeled by discrete nonlinear schrdinger equations ( nlses ) @xcite .\ndws are known in superfluids too , where they are formed by immiscible binary bose - einstein condensates ( becs ) , as predicted theoretically @xcite and demonstrated in experiments @xcite . in the mean - field approximation @xcite ,\nsuch settings are modeled by systems of nonlinearly coupled gross - pitaevskii equations ( gpes ) with the cubic self - repulsive nonlinearity , which are similar to coupled nlses describing the above - mentioned optical dws @xcite . in their stationary form , these equations coincide with coupled cubic ginzburg - landau equations modeling dws in dissipative patterns , such as interfaces between rolls with different orientations in large - area rayleigh - benard convection @xcite .    the analysis of the dws in bec was extended for broader settings , including linear interconversion between the immiscible components  ( this is possible when they represent two different hyperfine states of the same atom coupled by a resonant radiofrequency wave ) @xcite , dipolar @xcite and spinor ( three - component ) condensates @xcite , as well as the bec discretized by trapping in a deep optical - lattice ( ol ) potentials mering .\nfurthermore , the study of the dws was recently extended for immiscible binary becs  with three - particle collisions @xcite , in the case when the related losses may be neglected , the respective coupled gpes featuring the cubic - quintic repulsive nonlinearity @xcite .    in the\neffectively one - dimensional ( 1d ) setting , ultracold bosonic gases with strong inter - atomic repulsion may be cast in the tonks - girardeau ( tg ) state , which emulates the gas of non - interacting fermions @xcite , provided that the energy of the repulsive interaction between bosons exceeds their kinetic energy , while the opposite situation corresponds to the becphase in the bosonic gas ( a review of the tg model was given in ref .\nthe tg gas of hard - core bosons has been realized experimentally , using tight transverse confinement @xcite .\nin particular , a longitudinal ol potential was used to increase the effective mass in the trapped state , thus making the kinetic energy small enough @xcite .\nit is commonly known that gpes furnish very accurate description of the bec in atomic gases . a similar macroscopic model of the tg gas\nis offered by the nlse with the quintic self - repulsion term @xcite . in a rigorous form , the relevance of the corresponding sextic term in the free - energy density of the three - dimensional bosonic gas in its ground state , which reduces to the quasi-1d tg phase , was demonstrated in ref .\n@xcite , under condition @xmath0 , where @xmath1 , @xmath2 , and @xmath3 are , respectively , the inter - atomic repulsion strength , system s length , and the total number o atoms .\nthe quintic model was used in various contexts , including shock waves @xcite , dark @xcite and gap - mode @xcite solitons , as well as bright solitons supported by dipole - dipole interactions @xcite , and , recently , dws in immiscible binary tg gases @xcite .\nfurther , oscillation frequencies derived from fermionic hydrodynamic equations , which apply to the hard - core tg gas , were found to be close to their counte"}
{"prediction": "the primordial black hole abundance constraints and the power spectrum of the primordial black hole abundance constraints and the calculation of the power spectrum of the primordial black hole abundance constraints and the consequences of their evaporation  @xcite. practitionthere are tight constraints on the abundance of pbhs formed from their present day gravitational effects and the consequences of their evaporation. practitionthese limits can be used to constrain the power spectrum of the primordial density, or curvature, perturbations. practitionthe pbh constraints on the curvature power spectrum are fairly weak, being many orders of magnitude larger than the measurements on cos", "reference": "primordial black hole ( pbh ) abundance limits constrain the primordial power spectrum , and hence models of inflation , on scales far smaller than those probed by cosmological observations . \n single field inflation models which are compatible with all cosmological data can have large enough perturbations on small scales to overproduce pbhs , and hence be excluded . \n the standard formulae for the amplitude of perturbations do not hold for modes that exit the horizon close to the end of inflation however . \n we use a modified flow analysis to identify models of inflation where the amplitude of perturbations on small scales is large . for these models \n we then carry out a numerical evolution of the perturbations and use the pbh constraints on the power spectrum to eliminate models which overproduce pbhs . \n significant pbh formation can occur in models in which inflation can continue indefinitely and is ended via a secondary mechanism . \n we demonstrate that pbhs constrain these types of inflation models and show that a numerical evaluation of the power spectrum decreases the number of otherwise viable models of inflation .", "source_text": "<sec:other>\nprimordial black holes ( pbhs ) can form in the early universe via the collapse of large density perturbations  @xcite .\nthere are tight constraints on the abundance of pbhs formed from their present day gravitational effects and the consequences of their evaporation .\nthese limits can be used to constrain the power spectrum of the primordial density , or curvature , perturbations .\nthe pbh constraints on the curvature power spectrum are fairly weak , being many orders of magnitude larger than the measurements on cosmological scales .\nthey do , however , apply over a very wide range of scales and therefore provide a useful constraint on models of inflation .\npeiris and easther  @xcite have shown that there are single field inflation models , which are compatible with all cosmological observations , for which the perturbation amplitude on small scales is large enough to produce a significant density of pbhs .    for scales which exit the horizon close to the end of inflation\nthe standard ( stewart - lyth  @xcite ) formulae for the amplitude of perturbations do not hold . leach and liddle  @xcite carried out a numerical calculation of the evolution of perturbations for a quadratic inflationary potential .\nthey found that the perturbations on scales which exit the horizon close to the end of inflation were roughly an order of magnitude larger than predicted by the stewart - lyth formula ( see also ref .\n@xcite ) . therefore to fully exploit the power of pbh constraints on inflation models , a numerical calculation of the amplitude of perturbations on small scales is required .\nit has recently been shown  @xcite that pbhs can also form on scales which never leave the horizon .\nwe do not consider this possibility here .    in this paper\nwe use a modified flow analysis to identify inflation models where the perturbations at the end of inflation may be large enough for primordial black holes to be overproduced . for these models\nwe carry out a numerical evolution of the primordial perturbations and use the pbh constraints on the power spectrum to eliminate models which overproduce pbhs .\nwe describe the modified flow analysis in sec .\n[ flow ] and the evolution of perturbations and the calculation of the power spectrum in sec .\nwe apply the primordial black hole abundance constraints and present our results in sec .\n[ results ] and conclude with discussion in sec .  [ discuss ] .\nwe consider the hubble slow roll - parameters  @xcite : @xmath0 where @xmath1 is the planck mass and @xmath2 denotes differentiation with respect to the scalar field , @xmath3 .\nthe flow equations  @xcite encode the variation of the slow - roll parameters in terms of the number of e - foldings from the end of inflation , @xmath4}$ ] and provide a method for stochastically generating inflation models : @xmath5(^l\\lambda_h ) + ^{l+1}\\lambda_h \\ , ,    \\\\ & & \\hspace{50 mm } l\\ge 1                \\nonumber \\label{flowequations}\\end{aligned}\\ ] ] where @xmath6 and @xmath7 .\nfollowing kinney  @xcite we randomly chose ` initial ' values for the slow - roll parameters and @xmath8 , the number of e - foldings between cosmological scales exiting the horizon and the end of inflation , in the ranges : @xmath9 \\ , , \\\\\n\\nonumber \\epsilon_h&=&[0,0.8 ]   \\ , , \\\\    \\nonumber \\sigma_h&=&[-0.5,0.5 ] \\ , , \\\\\n\\nonumber ^2\\lambda_h \\equiv \\xi_h&=&[-0.05,0.05 ]   \\,,\\\\      \\nonumber ^3\\lambda_h&=&[-0.005,0.005 ]   \\ , , \\\\\n\\nonumber & ... & \\\\ ^{m+1}\\lambda_h&=&0 \\ , , \\label{hierarchy}\\end{aligned}\\ ] ] truncating the hierarchy at @xmath10 .\nwe then evolve the flow equations forward in time ( @xmath11 ) from @xmath12 until either @xmath13 or inflation ends with @xmath14 . in the former case\nwe calculate the cosmological observables , the spectral index , @xmath15 , its running , @xmath16 , and the scalar to tensor ratio , @xmath17 , using the initial values of the slow - roll parameters  @xcite : @xmath18   \\ , , \\\\\nr & = & \\epsilon_h [ 1-c_1(\\sigma_h+2\\epsilon_"}
{"prediction": "the flight management infrastructure ( fmi ) product is intended to keep the aircraft from interfering with preplanned observations on the sky.the flight management infrastructure ( fmi ) product is intended to keep the aircraft from interfering with preplanned observations on the sky.the flight management infrastructure ( fmi ) product is intended to keep the aircraft from interfering with preplanned observations on the sky.the flight management infrastructure ( fmi ) product is intended to keep the aircraft from interfering with preplanned observations on the sky.the flight management infrastructure ( fmi ) product is intended to keep the aircraft from interfering with preplanned observations on the sky.the autop", "reference": "sofia is a 2.5 meter airborne infrared telescope , mounted in a boeing 747sp aircraft . due to the large size of the telescope , \n only a few degrees of azimuth are available at the telescope bearing . \n this means the heading of the aircraft is fundamentally associated with the telescope s observation targets , and the ground track necessary to enable a given mission is highly complex and dependent on the coordinates , duration , and order of observations to be performed . \n we have designed and implemented a flight management infrastructure ( fmi ) product in order to plan and execute such missions in the presence of a large number of external constraints ( e.g. restricted airspace , international boundaries , elevation limits of the telescope , aircraft performance , winds at altitude , and ambient temperatures ) . \n we present an overview of the fmi , including the process , constraints and basic algorithms used to plan and execute sofia missions .", "source_text": "<sec:other>\nthe flight management infrastructure ( fmi ) product is intended to keep the aircraft from interfering with preplanned observations on the sky .\nit predicts the ground tracks necessary to execute its mission , and corrects the plan for actual conditions while airborne . to support this ,\nit contains both a planning component that can run on the ground and in the air , and an execution component that runs in the air .\nthe planning component manages a set of ordered observations and optional aircraft repositioning requests .\nthe execution component compares the plan to actual conditions in flight and requests headings ( indirectly ) from the autopilot .\nsofia mission planning differs from satellite or ground based observatory planning in a few key areas .\nmost importantly , the observatory position is a function of observation target history , which prevents observations from being considered as time - slots alone .\nassignment of flight dates is also nontrivial  targets can not be localized on the sky or the observatory will always fly in about the same direction ( requiring nearly equivalent dead time to return ) ; this suggests entire flight series should be considered at once , for greater target variety .\nflight planning and execution differs from conventional as well .\nall conventional aircraft fly from point to point along specified paths on the ground , and `` drift '' the aircraft to compensate for winds .\ntypical drift angles ( course - heading ) exceed 3@xmath0 , and the worst possible case approaches 30@xmath0 , so sofia can not necessarily observe in this manner .\nexpected winds can be planned for using a weather forecast .\ncorrecting course for _ unexpected _ winds can be accomplished by adjusting observation durations , by relocating the aircraft between observations , or by `` observation triage '' as a last resort .\nthis requires an astronomically - aware airborne monitoring function to compare current conditions to plan .\naircraft capabilities are a strong function of fuel weight , which argues against simple parametrizing by time , in favor of fuel .\nin addition to the geometrical and practical constraints described above , the sofia flight planning problem also has a number of external constraints , all of which prevent a truly automated , or even rigorously sequential , flight planning process . for instance , special use airspace ( sua ) incursions may require external approval , and it can not be known ahead of time whether such approval will be forthcoming in all cases .\nnational airspace boundaries require international agreements . over - ocean operations\nare prohibited for safety reasons for the first flights ; for later flights , fairly complex fuel reserve constraints are required .\ngross takeoff weight has a hard limit of 700,000 pounds , which limits the duration of sofia missions .\nsome science - driven constraints require interaction with scientists or detailed knowledge of the observations ; especially , trading off water vapor overburden estimates with altitude and duration , and for trading off observations against each other .\nprior to any particular mission , several iterations of flight planning are performed .\nthis is expected to include fully integrated automated flight planning ( frank , gross , & krkl 2004 ) , routinely .\nmanual choice of observation ( including order ) will occur subsequently . upon execution , replanning might occur if conditions are sufficiently different from assumptions .\nfigure  [ fig : sampleflight ] shows a color - processed screenshot of a simulated flight intended for april , 2008 , from palmdale , ca .\nactual conditions for the simulation shown differ from planned only by small timing errors of the order of several seconds between segments and at takeoff .\nas mentioned earlier , it is advantageous to consider entire flight series at once , in order to trade observations between flights .\nthe data structure supporting this is shown in fig .\n[ fig : "}
{"prediction": "is the most common method for determining the properties of nuclear matter. Theoretically, theoretically, theoretically, theoretically, and theoretically, theoretically, theoretically, and theoretically, theoretically, and theoretically, theoretically, and theoretically, theoretically, and theoretically, theoretically, and theoretically, theoretically, and theoretically, theoretically, and theoretically, theoretically, and theoretically, theoretically, and theoretically, theoretically, and theoretically", "reference": "we have simulated two - colour four - flavour qcd at non - zero chemical potential @xmath0 for quark number . \n simulations were performed on @xmath1 and @xmath2 lattices . \n clear evidence was seen for the formation of a colourless diquark condensate which breaks quark number spontaneously , for @xmath3 . \n the transition appears to be second order . \n we have measured the spectrum of scalar and pseudoscalar bosons which shows clear evidence for the expected goldstone boson . \n our results are in qualitative agreement with those from effective lagrangians for the potential goldstone excitations of this theory .", "source_text": "<sec:other>\nqcd at finite quark / baryon - number density at zero and at finite temperature describes nuclear matter\n. nuclear matter at high temperatures ( and possibly densities ) was certainly present in the early universe .\nneutron stars consist of dense cold nuclear matter .\nrhic and the cern heavy - ion program promise to produce hot nuclear matter in the laboratory . calculating the properties of high density nuclear matter could predict if and where strange matter could be produced .\nany method which can be used to determine the properties of nuclear matter could be adapted to nuclear physics calculations .\nfinite quark - number density is best achieved by introducing a chemical potential @xmath0 for quark - number , and using the grand - canonical partition function .\nunfortunately , this renders the euclidean - time fermion determinant complex , with a real part which can change sign .\nstandard lattice simulations , which rely on importance sampling , fail in this case . attempting to circumvent these problems by using canonical ( fixed quark number ) ensembles fail except at high temperatures @xcite because of sign problems .    until a simulation method is found\nwhich avoids these difficulties , it is useful to study models which exhibit _ some _ of the properties of qcd at high @xmath0 .\nnow it is expected that , at zero temperature , nuclear matter undergoes a phase transition at @xmath0 of order one third the mass of the nucleon .\nit has been proposed that at still higher @xmath0 the ground state is characterised by a diquark condensate @xcite .\nsuch a condensate would not only cause spontaneous breaking of baryon number , but would also spontaneously break colour . since colour is a gauge symmetry , such breaking\nis realized in the higgs mode .\nthus nuclear matter would become a colour superconductor at high @xmath0 .\nfor this reason we have simulated 2-colour qcd , i.e. su(2 ) yang - mills theory with fermion matter fields ( ` quarks ' ) in the fundamental representation of @xmath4 , and finite @xmath0 . as well as having colour confinement\nthis theory does exhibit diquark condensation as we shall demonstrate in this paper , but for @xmath5 , since the diquark ` baryons ' in the same multiplet as the pions , also have mass @xmath6 .\nfor @xmath7 the phenomenon is describable as a rotation of the condensate from the chiral to the diquark direction as predicted by effective lagrangian analyses @xcite .\nunlike in true ( 3-colour ) qcd , the diquark condensates are colourless , and the broken symmetry is realized in the goldstone mode , and there is no colour superconductivity , but rather superfluidity , as in liquid @xmath8he . despite this , we shall later argue that this theory is more similar to 2-flavour qcd than one might think ( see section 4 ) .\nsince 2-colour qcd has a non - negative determinant and pfaffian , even at non - zero @xmath0 , standard simulation methods can be used .\nwe use the hybrid molelcular - dynamics method and simulate the theory with 4 flavours of staggered quarks @xcite .\npfaffian simulations of a 4-fermion model including a diquark source term have been reported in @xcite .\nwe have run simulations at a moderately large quark mass and an intermediate gauge coupling on @xmath1 and @xmath9 lattices , i.e. at zero temperature .\nwe measured order parameters including the chiral and diquark condensates , the quark - number and energy densities , and the wilson line ( polyakov loop ) .\nthe larger lattice allowed us to observe finite size effects and , more importantly to measure the scalar and pseudoscalar meson and diquark masses , which include all the potential goldstone bosons in the theory .\npreliminary results from these simulations were reported at lattice2000 , bangalore @xcite .\nthe extension of these calculations to finite temperature was reported in a recent letter @xcite .\nthis work builds on early work with 8 quark flavours which presented far less conclusive results @xcite .\n"}
{"prediction": "the dipole - dipole interaction is ubiquitous in physics and for example responsible for the ever present van der waals force. practitionit is also important for envisaged quantum computers based on atoms or ions in traps. practitionit is also important for envisaged quantum computers based on atoms or ions in traps. practitionconsiderable interest in the literature has also been aroused by its cooperative effects on the radiative behavior of atoms @xcite. in an as yet unexplained experiment @xcite with two and three ba@xmath0 ions, which exhibit macroscopic light and dark periods, a large fraction of double and triple jumps was reported", "reference": "the mutual dipole - dipole interaction of atoms in a trap can affect their fluorescence . \n extremely large effects were reported for double jumps between different intensity periods in experiments with two and three ba@xmath0 ions for distances in the range of about ten wave lengths of the strong transition while no effects were observed for hg@xmath0 at 15 wave lengths . in this theoretical paper \n we study this question for configurations with three and four levels which model those of hg@xmath0 and ba@xmath0 , respectively . for two systems in the hg@xmath0 configuration \n we find cooperative effects of up to 30% for distances around one or two wave lengths , about 5% around ten wave lengths , and , for larger distances in agreement with experiments , practically none . \n this is similar for two v systems . \n however , for two four - level configurations , which model two ba@xmath0 ions , cooperative effects are practically absent , and this latter result is at odds with the experimental findings for ba@xmath0 .", "source_text": "<sec:other>\nthe dipole - dipole interaction is ubiquitous in physics and for example responsible for the ever present van der waals force .\nit is also important for envisaged quantum computers based on atoms or ions in traps .\nconsiderable interest in the literature has also been aroused by its cooperative effects on the radiative behavior of atoms @xcite . in an as yet unexplained experiment @xcite with two and three ba@xmath0 ions , which exhibit macroscopic light and dark periods , a large fraction of double and triple jumps was reported , i.e. jumps by two or three intensity steps within a short resolution time .\nthis fraction was orders of magnitudes larger than for independent ions .\nthe quantitative explanation of such a large cooperative effect for distances of the order of ten wave lengths of the strong transition has been found difficult @xcite .\nexperiments with other ions showed no observable cooperative effects @xcite , in particular none were seen for hg@xmath0 for a distance of about 15 wave lengths @xcite .\nmore recently , an unexpected high number of simultaneous quantum jumps in a linear chain of trapped ca@xmath0 ions was reported @xcite while no such effects were found in another experiment @xcite using the same ion species and a similar setup\n.    systems with macroscopic light and dark periods can provide a sensitive test for cooperative effects of the dipole - dipole interaction .\nthese periods can occur for multi - level systems where the electron is essentially shelved for some time in a meta - stable state without photon emission @xcite . for two v systems with macroscopic light and dark periods\nthe effect of the dipole - dipole interaction was investigated numerically in ref .\n@xcite and analytically in ref .\n@xcite and shown to be up to 30% in the double jump rate compared to independent systems .\nmonitoring the dipole - dipole interaction of two v systems via quantum jumps of individual atoms was investigated in ref .\nthe experimental systems of refs .\n@xcite are , however , not in the v configuration so that the results of ref .\n@xcite do not directly apply .\nthe experiment of ref .\n@xcite used two hg@xmath0 ions , with the relevant three levels as in fig .\n[ dsystem ] , which we call a d configuration .    from a theoretical point of view two such systems were studied in ref .\n@xcite for the special case @xmath1 , where @xmath2 is the distance and the wave lengths refer to the respective transitions of fig .\n[ dsystem ] , and for this case no cooperative effects were found .\nthe general case will be treated explicitly further below .\nthe cooperative effects found here are of similar magnitude as for v systems , and for distances of the above range the result of ref .\n@xcite is confirmed .\nour results are also in agreement with the experimentally observed absence of cooperative effects for distances of about 15 wave lengths @xcite .    the levels of ba@xmath0 used in the experiment of refs .\n@xcite are depicted in fig .\n[ 5niveau ] ( a ) .\nthe ground state @xmath3 and the two upper states @xmath4 and @xmath5 constitute a strongly driven fluorescing @xmath6 system which provides the light periods .\nonly when the system is in the ground state can the weak incoherent driving of the @xmath3 - @xmath7 transition populate the meta - stable @xmath5 state , with ensuing dark period .\ntherefore the details of the two upper states of the @xmath6 system play no significant role for the transition to a dark period , and therefore these two states are here replaced by an _ effective _ single level .\nthis leads to the four - level configuration of fig .\n[ 5niveau ] ( b ) .\nthe present paper is , to our knowledge , the first to theoretically investigate possible cooperative effects for two such four - level systems .\nsurprisingly , these effects turn out to be much smaller than for two v systems for distances @xmath8 , and this shows that cooperative effects sensitively depend on how the meta - stable level is p"}
{"prediction": "a cluster category is a certain 2-calabi - yau orbit category of the derived category of a hereditary abelian category.\\\\\\\\\\\\\\\\a cluster category is a certain 2-calabi - yau orbit category of the derived category of a hereditary abelian category.\\\\\\\\\\\\\\\\cluster categories were introduced in @xcite in order to give a categorical model for the combinatorics of fomin - zelevinsky cluster algebras @xcite.\\\\\\\\\\\\\\\\they are triangulated @xcite and admit ( cluster-)tilting objects, which model the clusters of a corresponding ( acyclic ) cluster algebra", "reference": "we define mutation on coloured quivers associated to tilting objects in higher cluster categories . \n we show that this operation is compatible with the mutation operation on the tilting objects . \n this gives a combinatorial approach to tilting in higher cluster categories and especially an algorithm to determine the gabriel quivers of tilting objects in such categories .    \n [ section ] [ lemma]proposition [ lemma]corollary [ lemma]theorem [ lemma]remark [ lemma]definition [ lemma]example", "source_text": "<sec:other>\na cluster category is a certain 2-calabi - yau orbit category of the derived category of a hereditary abelian category .\ncluster categories were introduced in @xcite in order to give a categorical model for the combinatorics of fomin - zelevinsky cluster algebras @xcite .\nthey are triangulated @xcite and admit ( cluster-)tilting objects , which model the clusters of a corresponding ( acyclic ) cluster algebra @xcite . each cluster in a fixed cluster algebra comes together with a finite quiver , and in the categorical model this quiver is in fact the gabriel quiver of the corresponding tilting object @xcite .\na principal ingredient in the construction of a cluster algebra is quiver mutation .\nit controls the exchange procedure which gives a rule for producing a new cluster variable and hence a new cluster from a given cluster .\nexchange is modeled by cluster categories in the acyclic case @xcite in terms of a mutation rule for tilting objects , i.e. a rule for replacing an indecomposable direct summand in a tilting object with another indecomposable rigid object , to get a new tilting object .\nquiver mutation describes the relation between the gabriel quivers of the corresponding tilting objects .\nanalogously to the definition of the cluster category , for a positive integer @xmath0 , it is natural to define a certain @xmath1-calabi - yau orbit category of the derived category of a hereditary abelian category .\nthis is called the _\n@xmath0-cluster category_. implicitly , @xmath0-cluster categories was first studied in @xcite , and their ( cluster-)tilting objects have been studied in @xcite .\ncombinatorial descriptions of @xmath0-cluster categories in dynkin type @xmath2 and @xmath3 are given in @xcite .    in cluster categories\nthe mutation rule for tilting objects is described in terms of certain triangles called _ exchange triangles_. by @xcite the existence of exchange triangles generalizes to @xmath0-cluster categories .\nit was shown in @xcite that there are exactly @xmath1 non - isomorphic complements to an almost complete tilting object , and that they are determined by the @xmath1 exchange triangles defined in @xcite .\nthe aim of this paper is to give a combinatorial description of mutation in @xmath0-cluster categories . _ a priori _\n, one might expect to be able to do this by keeping track of the gabriel quivers of the tilting objects .\nhowever , it is easy to see that the gabriel quivers do not contain enough information .    we proceed to associate to a tilting object a quiver each of whose arrows has an associated colour @xmath4 . the arrows with colour 0 form the gabriel quiver of the tilting object .\nwe then define a mutation operation on coloured quivers and show that it is compatible with mutation of tilting objects .\na consequence is that the effect of an arbitrary sequence of mutations on a tilting object in an @xmath0-cluster category can be calculated by a purely combinatorial procedure .\nour definition of a coloured quiver associated to a tilting object makes sense in any @xmath1-calabi - yau category , such as for example those studied in @xcite .\nwe hope that our constructions may shed some light on mutation of tilting objects in this more general setting .    in section 1 , we review some elementary facts about higher cluster categories . in section 2 , we explain how to define the coloured quiver of a tilting object , we define coloured quiver mutation , and we state our main theorem . in sections 3 and 4 , we state some further lemmas about higher cluster categories , and we prove certain properties of the coloured quivers of tilting objects .\nwe prove our main result in sections 5 and 6 . in sections 7 and 8\nwe point out some applications . in section 9\nwe interpret our construction in terms of @xmath0-cluster complexes . in section 10\n, we give an alternative algorithm for computing coloured quiver mutation .\nsection 11 discusses the example of @xmath0-cluster categories of dynkin type @"}
{"prediction": "the following section describes the mr model in more detail. distinguisthis paper explores the phenomenology of the standard model s minimal supersymmetric @xcite extension with a continuous @xmath1 symmetry ( hereafter called the ` mr model')@xcite. distinguisthis paper explores the phenomenology of the minimal supersymmetric @xcite extension with a continuous @xmath1 symmetry ( hereafter called the ` mr model')@xcite. distinguisthis model of low - energy supersymmetry has a much smaller - dimensional parameter space than the minimal supersymmetric model with a discrete @xmath3-", "reference": "we compute the one - loop corrections to the @xmath0 vertex in the @xmath1 symmetric minimal supersymmetric extension of the standard model . we find that the predicted value of @xmath2 is consistent with experiment if the mass of the lighter top squark is no more than 180 gev . \n furthermore , other data combines to place a lower bound of 88 gev on the mass of the light top squark . \n a top squark in this mass range should be accessible to searches by experiments at fnal and lep .    \n * @xmath0 in @xmath1 symmetric supersymmetry * 3em elizabeth h. simmons & yumian su 2em _ dept . of physics , boston university , + 590 commonwealth ave . , \n boston , ma 02215 _ \n 3em 3em    pacs : 12.60.jv , 13.38.dg , 14.80.ly    6em", "source_text": "<sec:other>\nthis paper explores the phenomenology of the standard model s minimal supersymmetric @xcite extension with a continuous @xmath1 symmetry ( hereafter called the ` mr model')@xcite .\nthis model of low - energy supersymmetry has a much smaller - dimensional parameter space than the minimal supersymmetric model with a discrete @xmath3-parity ( mssm @xcite ) . as a result , it has two attractive features .\nfirst , the mr model makes specific predictions of the values of a number of observables , such as the gaugino masses .\nin addition , the mr model is free of the superpotential term @xmath4 and the soft supersymmetry breaking terms @xmath5 that cause well - known theoretical difficulties in the mssm .\nwe focus , in particular on the recent measurements of @xmath2 @xmath6 which yield a value @xmath7 @xcite that differs markedly from the one - loop standard model prediction @xmath8 @xcite .\nthe oblique and qcd corrections to the @xmath9-quark and hadronic decay widths of the @xmath10 each largely cancel when the ratio is formed , making @xmath2 very sensitive to direct corrections to the @xmath11 vertex  especially those involving the heavy top quark .\nour work complements some recent papers on susy models with discrete r - parity .\nthe implications of the @xmath2 measurement for the mssm are discussed in refs .\n@xcite , @xcite and @xcite .\na region of the mssm parameter space that has some phenomenology similar to that of the mr model is studied in @xcite .\nthe following section describes the mr model in more detail .\nwe then compute the vertex corrections to @xmath2 in the mr model and find that the result is within @xmath12 of the experimental value so long as the lighter top squark is light enough ( and the charged higgs boson is heavy enough ) .\nsection 4 discusses additional constraints that place a lower bound on the mass of the lighter top squark .\nthe information that future experiments may yield is studied in section 5 ; ongoing and upcoming experiments at fnal and lep should be capable of confirming or excluding the mr model .\nthe last section briefly summarizes our findings .\nthe model explored in this paper is the minimal supersymmetric extension of the standard model in which @xmath3-parity is extended to a continuous @xmath13 symmetry .\nthe continuous @xmath3-symmetry is defined by assigning @xmath3 charges + 1 to the superspace coordinate @xmath14 , + 1 to matter superfields and 0 to higgs superfields . in terms of component fields ,\nall ordinary particles carry zero @xmath3 charge while their superpartners have non - zero @xmath3-charge .\nthe most general @xmath1-symmetric lagrangian is described by the superpotential @xmath15 where each term has @xmath16 , and the quark and lepton superfields @xmath17 @xmath18 have the usual @xmath19 gauge interactions .\nnote the absence of a @xmath4 term which would violate the @xmath1 symmetry .\nthe most general symmetry forbids majorana gaugino masses , the model contains an additional color octet chiral superfield to give a dirac mass to the gluino .\nthis field appears only in the soft supersymmetry breaking potential .\nthe gluino mass is relevant to this work in that it renders the 1-loop correction to @xmath2 from diagrams with internal gluinos and bottom squarks negligible compared to the effects of the diagrams considered here .\nwe will therefore not mention the color octet superfield further .\nthe effects of allowing the gluino to be extremely light in a @xmath1-symmetric model will be considered in future work . ]\nsoft supersymmetry breaking potential consistent with our symmetries and a gim - like mechanism to naturally suppress flavor - changing neutral currents is : @xmath20 where we neglect small yukawa - suppressed corrections to the superpartners masses .\nnote the characteristic absence of gaugino mass terms ( @xmath21 ) and trilinear scalar terms ( @xmath22 ) . for a more detailed description of the model\nwe refer the reader to  @xcite .\nthe non - stan"}
{"prediction": "the classical method of adding two integers of @xmath1-bits takes @xmath2 bit operations but the classical method of multiplying them takes @xmath3 bit operations.the classical method of adding two integers of @xmath1-bits takes @xmath2 bit operations but the classical method of multiplying them takes @xmath3 bit operations.the classical method of adding two integers of @xmath1-bit integers requires @xmath3 bit operations.the classical method of adding two integers of @xmath1-bit integers requires @xmath3 bit operations.the classical method of adding two integers of @", "reference": "multiplication is one of the most important operation in computer arithmetic . \n many integer operations such as squaring , division and computing reciprocal require same order of time as multiplication whereas some other operations such as computing gcd and residue operation require at most a factor of @xmath0 time more than multiplication . we propose an integer multiplication algorithm using nikhilam method of vedic mathematics which can be used to multiply two binary numbers efficiently .    \n integer multiplication , algorithm , computer arithmetic , vedic mathematics , computation", "source_text": "<sec:other>\nthe classical method of adding two integers of @xmath1-bits takes @xmath2 bit operations but the classical method of multiplying them takes @xmath3 bit operations .\ncomplexity of addition is optimal in number of bit operations , whereas optimal multiplication algorithm for integers is an open problem .\nthe classical approach to multiply two @xmath1-bit integers requires @xmath3 bit operations .\nkaratsuba multiplication [ 9 ] uses divide - and - conquer technique to multiply two @xmath1-bit integers in @xmath4 bit operations(logarithms are to the base 2 unless otherwise specified ) by replacing some of the multiplication by less costly addition and subtraction .\ntoom - cook algorithm further improves the above bound [ 3 ] .\ntoom - cook method is the generalization of karatsuba method which split each number to be multiplied in multiple parts [ 12 ] . given two large integers , toom - cook splits up multiplicand and multiplier into @xmath5 smaller parts each of length @xmath6 , and performs operations on the parts .\nas @xmath5 grows , one may combine many of the multiplication sub - operations , thus reducing the overall complexity of the algorithm . for @xmath7 toom - cook\nreduces 9 multiplication to 5 , with asymptotic complexity of @xmath8 .\nschonhage - strassen integer multiplication algorithm [ 10 ] uses fast fourier transform ( fft ) by selecting the principal roots of unity as evaluation point to perform multiplication in @xmath9 bit operations .\nfft method employs a divide - and - conquer strategy by taking advantage of the special properties of the complex root of unity to perform multiplication of two polynomials in only @xmath10 arithmetic complexity [ 4 ] .\nin fact many multiplication algorithms can viewed as schemes for the evaluation of polynomials then multiplication of their values and followed by interpolation .\ncurrently , the asymptotically fastest algorithm for multiplication of two @xmath1-bit integers is by furer [ 7 ] which runs in @xmath11 . where @xmath12 is iterated logarithm function [ 5 ] defined as : @xmath13 furer algorithm uses arithmetic over complex number .\nsame asymptotic bound can also be achieved using modular arithmetic [ 6 ] .\n+ the schonhage - strassen algorithm and furer algorithm are asymptotically fast but they are suited for extremely large numbers .\nfurer algorithm although asymptotically fastest , only achieves an advantage for astronomically large values and as such it is currently not used in practice .\nthe crossover points between these algorithms are usually very high when the algorithms are implemented [ 8 ] . for small inputs\neven karatsuba algorithm runs slower than the classical multiplication algorithm because of recursion overhead . in this paper\nwe use nikhilam sutra or method from vedic mathematics [ 11 ] to perform efficient multiplication for small inputs .\nnikhilam sutra performs large multiplication by converting it to small multiplication along with some addition and shifting operations . +\nthis paper is organized as follows .\nsection 2 describes background and motivation .\nsection 3 presents our proposed work , the multiplication algorithm and its features . in section 4\n, we present some applications .\nfinally , section 5 contains conclusion .\nthe simplest method to multiply two @xmath1-digit integers is using classical or long multiplication method which requires @xmath3 multiplication operations .\nwhereas to add or subtract two @xmath1-digit integers using traditional method requires at most @xmath1 number of addition or subtraction which is optimal in terms of number of addition / subtraction operation performed . to improve the @xmath3 bound of multiplication\n, several algorithms have been discovered .\nthe simplest one is karatsuba algorithm which is based on divide - and - conquer paradigm [ 1 ] .\nkaratsuba algorithm is based on the fact that two - digit multiplication can be done with only three instead of four multiplications required by standard"}
{"prediction": "withdrawalit has been known for a long time that the classical two - integral equilibrium theory in axisymmetric geometry is not sufficient to adequately describe the stellar discs of galaxies. in accordance with jeans theorem ( jeans 1915 )withdrawalit has been known for a long time that the phase space distribution function of a stellar system in a steady state depends only on the isolating integrals of the motion ; the binding energy @xmath0 and the vertical component of the angular momentum @xmath1 are isolating integrals in a stationary and axisymmetric system.withdrawalit is a fundamental property of all", "reference": "we present new equilibrium component distribution functions that depend on three analytic integrals in a stckel potential , and that can be used to model stellar discs of galaxies . \n these components are generalizations of two - integral ones and can thus provide thin discs in the two - integral approximation . \n their most important properties are the partly analytical expression for their moments , the disc - like features of their configuration space densities ( exponential decline in the galactic plane and finite extent in the vertical direction ) and the anisotropy of their velocity dispersions . \n we further show that a linear combination of such components can fit a van der kruit disc .    \n epsf rotate    = =    = =    = =    = =    # 1 # 1    # 1 # 1    @mathgroup@group    @mathgroup@normal@groupeurmn    @mathgroup@bold@groupeurbn    @mathgroup@group    @mathgroup@normal@groupmsamn    @mathgroup@bold@groupmsamn    = \" 019    = \" 016    = \" 040    = \" 336    = \" 33e    = =    = =    = =    = =    # 1 # 1    # 1 # 1    = =    = =    = =    = =    [ firstpage ]    galaxies : kinematics and dynamics  galaxies : stucture  stars : kinematics .", "source_text": "<sec:other>\nit has been known for a long time that the classical two - integral equilibrium theory in axisymmetric geometry is not sufficient to adequately describe the stellar discs of galaxies . in accordance with jeans theorem ( jeans 1915 )\n, the phase space distribution function of a stellar system in a steady state depends only on the isolating integrals of the motion ; the binding energy @xmath0 and the vertical component of the angular momentum @xmath1 are isolating integrals in a stationary and axisymmetric system .\nit is a fundamental property of all two - integral distribution functions @xmath2 that the dispersion of the velocity in the radial direction equals the dispersion in the vertical direction : we know that , for example , the disc of the milky way does not have that property  ( binney & merrifield 1998 ) .\nillustrations of other shortcomings of a two - integral model in a galactic context can be found in durand , dejonghe & acker  ( 1996 ) .\nthe introduction of a third integral of the motion helps to overcome these constraints : in that case , the velocity dispersions can be different in all the directions .\nnumerical experiments show that a third isolating integral seems to exist for most orbits in realistic galactic potentials  ( ollongren 1962 , innanen & papp 1977 , richstone 1982 ) .\nthis third integral can be taken into account numerically in the models by using extensions of schwarzschild s  ( 1979 ) orbit superposition technique  ( cretton et al .\n1999 , zhao 1999 , hfner et al .\nit is also possible to define an analytic third integral specific to particular orbital families  ( de zeeuw , evans & schwarzschild 1996 , evans , hfner & de zeeuw 1997 ) or an approximate global third integral  ( petrou 1983ab , dehnen & gerhard 1993 ) , but we choose to construct models with an exact analytic third integral by using a stckel potential  ( stckel 1890 , de zeeuw 1985 ) .\nit is not quite obvious to define suitable global distribution functions @xmath3 that depend on three exact analytic integrals and that can somewhat realistically represent our ideas of a real stellar disc .\nfor example , bienaym  ( 1999 ) made three - integral extensions of the two - integral parametric distribution functions described in bienaym & schaud  ( 1997 ) , but these ones were built to model the kinematics of neighbouring stars in the milky way only .\ndejonghe & laurent  ( 1991 ) also defined the three - integral abel distribution functions , but these ones could not provide very thin discs in the two - integral approximation .\nrobijn & de zeeuw  ( 1996 ) constructed three - integral distribution functions for oblate galaxy models , but they also had problems to recover the two - integral approximation .    in this paper\nwe continue the work of batsleer & dejonghe  ( 1995 ) , who constructed component distribution functions that are two - integral , but that can represent ( very ) thin discs when a judicious linear combination of them is chosen .\nwe use these components as a basis for new component distribution functions that are three - integral , of which the batsleer & dejonghe components are a special case .    in the next section\n, we outline some fundamentals of two - integral equilibrium systems and we show how to model discs with a finite extent in the vertical direction . in section 3 , we present some general facts about stckel potentials and we present new analytic three - integral distribution functions that can represent stellar discs .\nan analytical expression for the moments of these distribution functions is calculated in section 4 . in the next section\n, we discuss their physical properties and show their realistic disc - like character . finally ,\nin section 6 , we show that these distribution functions can be used as basis functions in the modeling of a van der kruit disc . for the conclusions ,\nwe refer to section 7 .\nwe denote the gravitational potential in cylindrical coordinates @xmath4 by @xmath5 . the tw"}
{"prediction": "@xcite in the high - frequency regime,the control and manipulation of single electrons in mesoscopic systems constitutes one of the key ingredients in nanoelectronics.@xcite in the high - frequency regime,the control and manipulation of single electrons in mesoscopic systems constitutes one of the key ingredients in nanoelectronics.@xcite in the high - frequency regime,the control and manipulation of single - electron sources@xcite in the high - frequency regime has attracted a great interest due to their potential application in quantum electron optics experiments, in metrology, and in quantum information processing based on fermionic systems.@", "reference": "we analyze the dynamics of a single - level quantum dot with coulomb interaction , weakly tunnel coupled to an electronic reservoir , after it has been brought out of equilibrium , e.g. by a step - pulse potential . \n we investigate the exponential decay towards the equilibrium state , which is governed by three time scales . \n in addition to the charge and spin relaxation time there is a third time scale which is independent of the level position and the coulomb interaction . \n this time scale emerges in the time evolution of physical quantities sensitive to two - particle processes .", "source_text": "<sec:other>\nthe control and manipulation of single electrons in mesoscopic systems constitutes one of the key ingredients in nanoelectronics .\nthe study of single - electron sources@xcite in the high - frequency regime has attracted a great interest due to their potential application in quantum electron optics experiments , in metrology , and in quantum information processing based on fermionic systems.@xcite in this work we study the time evolution of a quantum dot ( qd ) tunnel coupled to a single electronic reservoir , as depicted schematically in fig .  [ fig_scheme](a ) . in the presence of some time - dependent voltage modulations ,\nthis system defines the building block of the typical single - electron source , namely the mesoscopic capacitor.@xcite in the linear - response regime , the relaxation behavior of such a mesoscopic capacitor has been extensively studied theoretically@xcite and experimentally,@xcite revealing the quantization of the charge relaxation resistance.@xcite on the other hand , the application of _ nonlinear _ periodic potentials to the mesoscopic capacitor yields the controlled emission and absorption of electrons at giga - hertz frequencies.@xcite from these experiments the average charge as well as current correlations@xcite after each cycle of the potential applied have been extracted .\nthese results demonstrate the importance of investigating the dynamics of this kind of single - electron sources . in some of the recent realizations@xcite\nthe coulomb interaction is weak ; however , in small - sized qds the coulomb blockade is , in general , strong and it is , therefore , desirable to include it in the theoretical analysis @xcite since it may even dominate time - dependent phenomena , see e.g. ref .  .\nthe time - evolution of interacting quantum dots after the coupling to the leads has been switched on , has , e.g. , been studied in refs .   and references therein .    , coupled to a normal lead with a tunneling strength @xmath0 .\ndot occupations can be measured via the current passing through a nearby quantum point contact ( qpc ) capacitively coupled to the dot .\nb ) qd attached to an additional superconducting contact .\nc ) qd coupled to a ferromagnetic lead . ]    here we investigate the exponential relaxation of a qd towards its equilibrium state after its has been brought out of equilibrium by applying , e.g. , a voltage step pulse .\nwe consider a voltage pulse that affects the occupation of only a single orbital energy level .\nthe level can be spin split due to coulomb interaction . in an earlier work,@xcite some of the present authors investigated the decay of charge and spin of such a single level qd .\nit was found that the relaxation of charge and spin are given by rates which differ from each other due to coulomb repulsion . since the reduced density matrix of a qd with a single orbital level with spin is four dimensional , there are thus three rates which govern the relaxation of the diagonal elements of the density matrix towards equilibrium ( plus one which is always zero and corresponds to the stable stationary state ) .\nin addition to the rates that govern charge and spin there is a third rate that appears in the relaxation of a single level qd with spin and with interaction .\nthis additional rate is the subject of this paper .\ninterestingly , this additional time scale is independent of the interaction and of the dot s level position .\nit is shown to be related to two - particle effects and appears , e.g. , in the time - evolution of the mean squared deviations of the charge from its equilibrium value .\nwe study in detail the perturbations leading to a relaxation of the system with the additional decay rate only , and find that it is indeed related to two - particle correlations .\nwe also propose a procedure to separately read out the different relaxation rates occurring in the dynamics of the qd exploiting the sensitivity of a nearby quantum point contact to the occupation of t"}
{"prediction": "the chemical self - organization is a hallmark of a far - from - equilibrium dynamics, therefore it appears difficult to reconcile with a common - sense chemical reaction scheme based on the law of mass action applied to a few selected reactions@xcite.during the last two decades, a number of new paradigms for understanding complex living systems have emerged.these include, e.g. theory of dynamical systems, theory of complexity, nonlinear dynamics, evolutionary physics, and critical phenomena@xcite. among these, chaotic attractors, ( multi-)fractals, self - assemblies, dissipative structures and self - organization represent some", "reference": "mesoscopic dynamics of self - organized structures is the most important aspect in the description of complex living systems . \n the belousov  zhabotinsky ( b  z ) reaction is in this respect a convenient testbed because it represents a prototype of chemical self - organization with a rich variety of emergent wave - spiral patterns . using a multi - state stochastic hotchpotch model , \n we show here that the mesoscopic behaviour of the non - stirred b  z \n reaction is both qualitatively and quantitatively susceptible to the description in terms of stochastic multilevel cellular automata . \n this further implies that the mesoscopic dynamics of the non - stirred b  z reaction results from a delicate interplay between a ) a maximal number of available states within the elementary time lag ( i.e. a minimal time interval needed for demise of a final state ) and b ) an imprecision or uncertainty in the definition of state . \n if either the number of time lags is largely different from 7 or the maximal number of available states is smaller than 20 , the physicochemical conditions are inappropriate for a formation of the wave - spiral patterns . \n furthermore , a white noise seems to be key for the formation of circular structures ( target patterns ) which could not be as yet systematically explained in existing models .", "source_text": "<sec:other>\nduring the last two decades , a number of new paradigms for understanding complex living systems have emerged .\nthese include , e.g. theory of dynamical systems , theory of complexity , nonlinear dynamics , evolutionary physics , and critical phenomena@xcite . among these , chaotic attractors , ( multi-)fractals , self - assemblies , dissipative structures and self - organization represent some of the most promising recent concepts .\na particularly important testbed for a conceptualization of pattern formation in self - organizing systems is the b  z reaction@xcite which belongs among the most extensively studied examples of chemical self - organization .\nhowever , despite decades of intensive research , there are still ongoing controversies over the actual chemical kinetics ( i.e. details of rates of chemical reactions involved ) and the mesoscopic dynamics ( i.e. exact nature and mechanism of patterns formation at the mesoscopic scale ) of the b  z reaction@xcite .\nthe b  z reaction is considered as a textbook example of the so - called excitable medium@xcite . majority of available chemical models which aim to explain the chemical self - organization are based on the standard reaction - diffusion analysis and the law of mass action applied to a few selected reactions@xcite . on the other hand ,\nself - organization is a hallmark of a far - from - equilibrium dynamics which appears difficult to reconcile with a common - sense chemical reaction scheme based on the law of mass action .\nturing patterns that appear in some reaction - diffusion models are often considered as a theoretical embodiment of the b \nz patterns@xcite .\nthis is wrong for at least three reasons : turing patterns ( a ) can explain only wave b  z patterns but not spirals@xcite , ( b ) appear only at specific parameter values in the reaction - diffusion equations , therefore they are unstable under fluctuations of parameters ( in contrast to experiments where patterns are observably robust ) , ( c ) are stable solutions of turing s reaction - diffusion equations while , in the experiment , we observe a dynamic system on a trajectory through the state space towards a limit cycle with alternating spirals and wave fragments .    the mesoscopic description of the b  z reaction is typically modeled with a cyclic cellular automaton which often generates patterns similar to the b  z wave patterns found near to the final stage of the reaction .\nthe morphological characterization of patterns is pivotal in these approaches while chemical aspects are often of a secondary interest .\nso far , mesoscopic studies of the b  z reaction have been limited to a low - level cellular automata@xcite which can reasonably well account only for some of the observed b \nz wave patterns , while it is as yet unclear how to generalize these approaches to obtain a full - fledged evolution of wave patterns together with dynamics of spiral patterns .\nto the best of our knowledge , the influence of the number of levels has been systematically studied only in one case@xcite while most of the systematic studies in the literature have been confined to maximally 8 levels@xcite .    in order to numerically implement a hotchpotch model ,\nwe have adopted an approach based on the version of wilensky netlogo model@xcite . in our case\nthe model is limited to 200 achievable state levels and simulated on a square 50 @xmath0 50 grid .\nafter a random setup of the space distribution of initial centers of @xmath1 $ ] as @xmath2 where @xmath3 is the maximally achievable number of levels of the cell state . the model at each time step\n@xmath4 may proceed in four possible ways :    1 .\nwhen a cell is at the @xmath5 , so - called _ quiescent _ , it may be `` infected '' by surrounding cells according to the equation @xmath6 where @xmath7 and @xmath8 is a number of cells at the @xmath9 and @xmath10 , respectively , @xmath11 and @xmath12 are characteristic constants of the process and @xmath3 is a maximu"}
{"prediction": "the cosmic ray energy spectrum is nearly featureless over ten orders of magnitude in energy, from @xmath0 ev to @xmath1 ev, with the differential flux falling approximately as @xmath2.the cosmic ray energy spectrum is nearly featureless over ten orders of magnitude in energy, from @xmath0 ev to @xmath1 ev, with the differential flux falling approximately as @xmath2.the cosmic ray energy spectrum is nearly featureless over ten orders of magnitude in energy, from @xmath0 ev to @xmath1 ev.the cosmic ray energy spectrum is nearly featureless over ten orders of", "reference": "the hires collaboration has recently announced preliminary measurements of the energy spectrum of ultra - high energy cosmic rays ( uhecr ) , as seen in monocular analyses from each of the two hires sites . \n this spectrum is consistent with the existence of the gzk cutoff , as well other aspects of the energy loss processes that cause the gzk cutoff . \n based on the analytic energy loss formalism of berezinsky _ et al . \n _ , the hires spectra favor a distribution of extragalactic sources that has a similar distribution to that of luminous matter in the universe , both in its local over - density and in its cosmological evolution .", "source_text": "<sec:other>\nthe cosmic ray energy spectrum is nearly featureless over ten orders of magnitude in energy , from @xmath0 ev to @xmath1 ev , with the differential flux falling approximately as @xmath2 .\nthere are three small , though widely discussed , features : the `` knee '' , a hardening of the spectrum at @xmath3 ev ; the `` second knee '' , another hardening at about @xmath4 ev ; and the `` ankle '' , a softening of the spectrum at about @xmath5 ev .\nthese features may represent changes in the sources , composition or dynamics of the cosmic rays .\ntwo often asked questions are : how do cosmic rays come to have such high energies ( a joule or more of kinetic energy in a proton or other sub - atomic particle ) , and does the spectrum continue above @xmath1 ev ?    there are two types of models describing the sources of ultra - high energy cosmic rays ( uhecrs ) : astrophysical models ( `` bottom - up '' ) , in which cosmic rays are accelerated to very high energies by magnetic shock fronts moving though plasmas ; and cosmological models ( `` top - down '' ) , in which the cosmic rays are the result of the decays of super heavy particles which are relics of the big bang .\ni will only be discussing the former .\none can evaluate the plausibility of various astrophysical sources by considering the magnetic field of the object and its size.@xcite the overall magnetic field contains the nascent cosmic rays during their acceleration and thus must be large enough to keep the cosmic rays within the object .\nsmaller objects need larger fields ; larger objects , smaller fields . by this criterion\nwe have several candidate sources : neutron stars , active galactic nuclei ( agn ) and clusters of galaxies among others .\nall these sources could plausibly , by the above argument , give cosmic rays at @xmath1 ev , but , in all cases , one is pushing the bounds of plausibility at the highest energies .\nif uhecrs are extragalactic , then they must traverse the intergalactic medium in order to be observed .\nthis medium is filled with cosmic microwave background ( cmb ) photons , which should lead to a fourth , and not so small , feature of the uhecr spectrum . because of their large kinetic energies , uhecrs interact with the cmb to produce resonances ( in the case of protons ) or to dissociate ( in the case of nuclei ) . in the proton case\n, the resonance ( e.g. @xmath6 ) will decay quickly into proton or neutron and a meson ( e.g. @xmath7 ) . in either case ,\nthe result is a reduction in the energy of the leading particle . at somewhat lower energies ,\ncosmic rays lose energy by creating electron - positron pairs in their interaction with the cmb .\nthese energy loss mechanisms imply that there should be a sharp reduction in the uhecr flux above @xmath8 ev , assuming the uhecrs are protons and that they come from distances greater than a few tens of megaparsecs .\nnuclei should have an even lower energy threshold .\nthis fact , first pointed out by greisen , zatsepin and kuzmin , has become known as the gzk cutoff.@xcite by measuring the shape of the uhecr spectrum and , crucially , modeling the spectrum at the source , one can hope to deduce which of the plausible sources listed above , if any , contribute to the uhecrs we see .\nif uhecrs are produced in our galaxy they are not subject to the gzk cutoff . however , there are no plausible astrophysical accelerators of uhecrs within our galaxy\n. any such object would appear as a point source in a map of the sky made with uhecrs , due to the short propagation distances and relatively weak magnetic fields .\nno such point source has been observed .\nuhecrs have a very low flux , so one must have a large collection area to obtain a reasonable event rate .\nthis precludes direct observations of uhecr above the earth s atmosphere in satellite experiments .\nhowever , one may also use that atmosphere as a giant calorimeter , because uhecrs create extensive air showers ( eass ) when they encounter the atmosp"}
